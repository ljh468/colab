{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lecture07_A Friendly Introduction to CNN..ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPRTvdr9Lq2Hcp8xfBqR+TN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZI45jCVNBrS4"},"source":["# **CNN 실습**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcmQxVsK43Y9","executionInfo":{"status":"ok","timestamp":1630041451068,"user_tz":-540,"elapsed":8090,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"26eb29c0-66af-4907-8bc1-b4db446a68f5"},"source":["import tensorflow as tf\n","import numpy as np                   # advanced math library\n","import matplotlib.pyplot as plt      # MATLAB like plotting routines\n","import random                        # for generating random numbers\n","\n","from tensorflow.keras.models import Sequential  # Model type to be used\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation\n","from tensorflow.keras.datasets import mnist     # MNIST dataset is included in Keras\n","from tensorflow.keras.utils import to_categorical, plot_model\n","\n","print(tf.__version__) # find the version number (should be 2.x+)\n","\n","# 그래픽카드 유무 확인 및 메모리 확장 설정\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  print('사용가능한 GPU 갯수: ',len(gpus), '\\n')\n","      \n","  try:\n","    # 프로그램이 실행되어 더 많은 GPU 메모리가 필요하면, 텐서플로 프로세스에 할당된 GPU 메모리 \n","    # 영역을 확장할 수있도록 허용\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","\n","  except RuntimeError as e:\n","    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n","    print(e)\n","\n","# 설치된 GPU 상세내용 확인\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":39,"outputs":[{"output_type":"stream","text":["2.6.0\n","사용가능한 GPU 갯수:  1 \n","\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 17295651951942739028\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 11345264640\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 7343128476044421674\n","physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LaAuJHMjGSfV"},"source":["## **이미지 미리보기**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"k2etA001GXeu","executionInfo":{"status":"ok","timestamp":1630041451869,"user_tz":-540,"elapsed":821,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"e9fa36cd-7c9e-43e6-dd46-090735dd3f52"},"source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Original 데이터 확인\n","print('X_train shape: {}\\tY_train shape: {}\\n'.format(x_train.shape, y_train.shape))\n","print('X_test shape: {}\\tY_test shape: {}\\n'.format(x_test.shape, y_test.shape))\n","\n","np.set_printoptions(linewidth=600, precision=2) # linewidth = 라인 최대 글자수, precision: 소수점이하 자리수\n","\n","# Browsing Original Dataset\n","\n","print('\\n',y_train[0: 9])\n","print('\\n',x_train[0])\n","\n","fig = plt.figure(figsize=(6,6)) # Width, height in inches.\n","fig.subplots_adjust(hspace=0.7)\n","\n","plt.imshow(x_train[0], cmap='gray') \n","plt.colorbar()   \n","plt.show()"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","X_train shape: (60000, 28, 28)\tY_train shape: (60000,)\n","\n","X_test shape: (10000, 28, 28)\tY_test shape: (10000,)\n","\n","\n"," [5 0 4 1 9 2 1 3 1]\n","\n"," [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n"," [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"I0n2OwTtBvW6"},"source":["## **데이터 전처리**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csIyz_vq7AFV","executionInfo":{"status":"ok","timestamp":1630041665419,"user_tz":-540,"elapsed":314,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"4af065b4-fffb-4c28-bd5e-986c63f928f6"},"source":["# Step 1 : Data Preparation\n","# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","num_labels = len(np.unique(y_train))\n","\n","# Reshape (CNN은 3차원으로 )\n","image_size = x_train.shape[1]\n","\n","x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n","x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n","\n","# Normalizing\n","x_train = x_train/255.\n","x_test = x_test/255.\n","\n","# One-Hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# 데이터 확인\n","print('X_train shape: {}\\tY_train shape: {}\\n'.format(x_train.shape, y_train.shape))\n","print('X_test shape: {}\\tY_test shape: {}\\n'.format(x_test.shape, y_test.shape))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["X_train shape: (60000, 28, 28, 1)\tY_train shape: (60000, 10, 2)\n","\n","X_test shape: (10000, 28, 28, 1)\tY_test shape: (10000, 10, 2)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"50bhOqp4B1Pd"},"source":["## **모델 구성**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75HBfWABA4Lx","executionInfo":{"status":"ok","timestamp":1630041704957,"user_tz":-540,"elapsed":307,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"d4c7d7b5-cb1a-4dca-b42c-8b487f1414f7"},"source":["# Step 2 : Model construction\n","\n","input_shape = (image_size, image_size, 1)\n","batch_size = 128\n","kernel_size = 3 # 한 필터의 사이즈 3 by 3  # 28 - 3 + 1 = 26\n","pool_size = 2 # 4를 1로 줄임\n","filters = 64 # 3 * 3 필터가 64개\n","dropout = 0.2\n","\n","# Model is a stack of CNN-ReLU-MaxPooling\n","\n","model = Sequential()\n","\n","model.add(Conv2D(filters = filters,\n","                 kernel_size = kernel_size,\n","                 activation = 'relu',\n","                 input_shape = input_shape)) # 26 * 26 * 64 을 결과가 나옴\n","model.add(MaxPooling2D(pool_size))\n","\n","model.add(Conv2D(filters = filters,\n","                 kernel_size = kernel_size,\n","                 activation='relu'))\n","model.add(MaxPooling2D(pool_size))\n","\n","model.add(Conv2D(filters = filters,\n","                 kernel_size = kernel_size,\n","                 activation = 'relu'))\n","\n","# Dense는 1차원 벡터이기에 연결하기 위해 평탄화\n","model.add(Flatten())\n","# dropout added as regularizer\n","# 드롭아웃 추가\n","model.add(Dropout(dropout))\n","\n","# output layer is 10-dim one-hot vector\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))\n","\n","model.summary()"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 576)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 576)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 1154      \n","_________________________________________________________________\n","activation (Activation)      (None, 2)                 0         \n","=================================================================\n","Total params: 75,650\n","Trainable params: 75,650\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oyZWM6wID8cn"},"source":["## **모델 컴파일**"]},{"cell_type":"code","metadata":{"id":"Mrk1HzDyA_dp","executionInfo":{"status":"ok","timestamp":1630041706809,"user_tz":-540,"elapsed":305,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["# Step 3 : Model compile\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = 'adam',\n","              metrics=['accuracy'])\n"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Rmc-LbAEVjv"},"source":["## **모델 학습**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nWYAQQo5EZTL","executionInfo":{"status":"error","timestamp":1630041707881,"user_tz":-540,"elapsed":5,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"ba5117c2-7782-499f-e015-418ace520310"},"source":["import time\n","start = time.time()\n","\n","# Step 4: Model fit\n","\n","model.fit(x_train, y_train, epochs=10, batch_size=batch_size)\n","\n","end = time.time()\n","print('Execution time in seconds =',end-start)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-3fd3085d5297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 4: Model fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1666 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 10, 2) and (None, 2) are incompatible\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JGSv2fCwE_Tq","executionInfo":{"status":"error","timestamp":1630041708307,"user_tz":-540,"elapsed":5,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"d17edd67-b843-4f0a-a119-5d26aad5f5ca"},"source":["# 모델 평가 출력은 99.2%의 최대 테스트 정확도를 보여주며, 이는 3계층 네트워크에서 달성될 수 있습니다.\n","# Adam Optimizer(드롭아웃=0.2)를 사용하여 레이어당 64개의 피쳐 맵을 제공합니다. CNN은 매개 변수가 더 효율적이고 더 높습니다.\n","# MLP보다 정확합니다.\n","# CNN도 마찬가지로 순차 데이터, 이미지, 비디오에서 표현을 학습하는 데 적합합니다.\n","\n","_, acc = model.evaluate(x_test,\n","                        y_test,\n","                        batch_size=batch_size,\n","                        verbose=0)\n","print('\\nTest accuracy : %.1f%%' %(100.0 * acc))"],"execution_count":48,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-014fd16fa30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         verbose=0)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTest accuracy : %.1f%%'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1330 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1270 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1666 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 10, 2) and (None, 2) are incompatible\n"]}]},{"cell_type":"markdown","metadata":{"id":"AUoAXbKOJ4I1"},"source":["# **How do Convolutional Neural Networks work?**\n","\n","Link 1: [How do Convolutional Neural Networks work?](https://e2eml.school/how_convolutional_neural_networks_work.html)\n","\n","Link 2: [Youtube Video](https://www.youtube.com/watch?v=FmpDIaiMIeA&t=103s)\n"]},{"cell_type":"markdown","metadata":{"id":"VkLtMzXfLVtk"},"source":["# 작동원리\n","\n","  1. Convolution\n","  2. Pooling\n","  3. ReLU Activation\n","  4. Deep Learning\n","  5. Fully Connected Layers"]},{"cell_type":"markdown","metadata":{"id":"UYHA5en1J5z9"},"source":["## Convolution\n","\n","아래 그림과 같이 컴퓨터에게 두 이미지중 하나를 제시하고 X와 O를 구분하게 하는 단순한 모형을 생각해보자.\n","\n","<img src = 'https://e2eml.school/images/cnn1.png'>\n","\n","제시되는 이미지는 축소(shrunken), 약간의 변형(deformed), 이동(shifted), 회전(rotation)이 된 그림일 수도 있다.\n","\n","<img src = \"https://e2eml.school/images/cnn2.png\">\n","\n","컴퓨터에게 이미지는 각 pixel에 숫자가 들어간 2차원 행렬로 인식된다. 우리 예에서는 흰색은 1, 흑색은 -1로 표시하였다."]},{"cell_type":"markdown","metadata":{"id":"wWYUE2GpLKMj"},"source":["## Features (Patterns, Representations)\n","<img src='https://e2eml.school/images/cnn3.png'>\n","\n","\n","CNN은 이미지를 여러개의 조각(patch, piece)으로 나누어 piece-by-piece로 패턴을 비교합니다.\n","\n","  - CNN은 전체 이미지 매칭 방식보다 유사성을 훨씬 더 잘 볼 수 있습니다.\n","\n","<img src = 'https://e2eml.school/images/cnn4.png'>\n","\n","  - 각 기능은 작은 2차원 값의 배열인 미니 이미지와 같습니다.\n","  - 기능은 이미지의 공통적인 측면과 일치합니다.\n","\n","\n","X의 경우 대각선(Diagonal Lines) feature와 크로스(X) feature가 그림에서 나온 여러개의 패치에서 일치 또는 유사한 경우를 찾게될 것이다.\n","\n","1. Convolution\n","\n","이미지가 처음 제시되었을 때 CNN은 정확히 어느 부분에 주어진 Feature가 match되는지 알 수 없기때문에 부분부분 옮겨 가면서 일치 또는 유사 여부를 확인하게 된다.이 과정에 사용되는 수학이 Convolution(합성곱)이며 이때 부분 부분 옮겨 가면서 사용되는 Feature를 필터(Filters)라고 한다.\n","\n","<img src=\"https://e2eml.school/images/cnn6.png\">\n"]},{"cell_type":"markdown","metadata":{"id":"UGeayNrRKLjo"},"source":["\n","## 합성곱 연산\n","\n","    ```\n","    이미지의 패치와 피쳐의 일치를 계산하려면\n","    (1) 피쳐의 각 픽셀에 이미지의 해당 픽셀 값을 곱하기만 하면 됩니다.\n","    (2) 그 다음 답을 합산하여 피쳐의 총 픽셀 수로 나눈다.\n","    ```\n","\n","- 일치하는 모든 픽셀은 1이 됩니다.\n","- 마찬가지로 불일치는 -1입니다.\n","- 피쳐의 모든 픽셀이 일치하는 경우 해당 픽셀을 합산하여 총 픽셀 수로 나누면 1이 됩니다.\n","- 마찬가지로 기능의 픽셀 중 이미지 패치와 일치하는 것이 없으면 답은 -1입니다.\n","\n","이렇게 해서 얻어진 2차원 행렬은 적용된 필터와 일치/유사/불일치하는지를 보여주는 지도(map)라 할 수 있으며 또한 원이미지에 필터를 적용한 축소된 이미지라 할 수있다.\n","\n","- 1에 가까운 값은 강한 일치를 나타냅니다.\n","- -1에 가까운 값은 우리 기능의 사진에 대한 강한 일치를 보여줍니다.\n","- 0에 가까운 값은 일치하는 항목이 없음을 나타냅니다.\n","\n","이 과정을 우리가 설정한 모든 필터(우리의 예에서는 3개)에 적용하면 이미지 셋( a set of 3 filtered images)을 구할 수 있다.\n","\n","<img src='https://e2eml.school/images/cnn7.png'>\n","\n","\n","    ```\n","    CNN이 어떻게 컴퓨터를 독차지 하는지 쉽게 알 수 있다.\n","    냅킨 뒷면에 CNN을 스케치할 수 있지만 덧셈, 곱셈, 나눗셈의 수는 빠르게\n","    증가할 수 있습니다.\n","    ```"]},{"cell_type":"markdown","metadata":{"id":"8QcF27mdPU2k"},"source":["## Pooling\n","\n","  Pooling은 CNN의 핵심 요소중 하나로서 큰 사이즈의 이미지를 중요한 정보는 유지하면서 축소시키려는 기법이다.\n","\n","  <img src='https://e2eml.school/images/cnn8.png'>\n","\n","- 실제로는 측면의 창 2~3픽셀과 2픽셀의 단계가 잘 작동합니다.\n","- 풀링 후 이미지는 약 1/4의 픽셀을 가집니다.\n","- 각 창의 최대값을 유지하기 때문에 각 기능의 최적 맞춤을 창 내에서 유지합니다.\n","- 풀링 레이어는 이미지 또는 이미지 컬렉션에서 풀링을 수행하는 작업입니다.\n","- 출력은 이미지 수는 같지만 각각 더 적은 픽셀을 가집니다.\n","- 이는 컴퓨팅 부하 관리에도 도움이 됩니다.\n","\n","  <img src='https://e2eml.school/images/cnn9.png'>\n"]},{"cell_type":"markdown","metadata":{"id":"LZdu1OJxPk6f"},"source":["\n","## Rectified Linear Units (ReLU)\n","\n","  <img src='https://e2eml.school/images/cnn10.png'>\n","  \n","- 이 프로세스에서 작지만 중요한 구성 요소는 교정 선형 장치 또는 ReLU입니다.\n","- 또한 수학은 매우 간단합니다. 음수가 발생할 때마다 0으로 바꿉니다.\n","    \n","$$\n","R(z) =  max(z,0) =\n","  \\begin{cases}\n","\t\t\t0, & \\text{for $z \\lt 0$}\\\\\n","      z, & \\text{for $z \\ge 0$}\n","\t\\end{cases}\n","$$\n","\n","- 이것은 학습된 값이 0에 가깝게 고착되거나 무한대로 폭발하는 것을 방지함으로써 CNN이 수학적으로 건강하게 유지하도록 도와줍니다. CNN의 핵심이죠\n","\n","  <img src='https://e2eml.school/images/cnn11.png'>\n","\n","  ReLU 레이어의 출력은 모든 음수 값이 제거된 상태에서 입력되는 것과 크기가 같습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"y6_5XEGmP35L"},"source":["## Deep learning\n","\n","  <img sr = 'https://e2eml.school/images/cnn12.png'>\n","\n","- 각 계층(2차원 배열)에 대한 입력은 출력(2차원 배열)과 매우 유사합니다. 그렇기 때문에 우리는 그것들을 레고 벽돌처럼 쌓을 수 있습니다.\n","- 원시 이미지는 필터링, 수정 및 풀링되어 축소된 피쳐 필터링된 이미지 세트를 만듭니다. 이것은 필터링되고 축소될 수 있습니다.\n","- 매번 기능이 더 커지고 복잡해지며 이미지는 더 작아집니다.\n","- 이렇게 하면 아래쪽 레이어가 가장자리나 밝은 점과 같은 이미지의 단순한 측면을 나타낼 수 있습니다.\n","- 레이어가 높을수록 모양이나 패턴과 같은 이미지의 정교한 측면을 나타낼 수 있습니다. \n","- 예를 들어, 사람 얼굴에 대해 훈련된 CNN에서 가장 높은 층은 분명히 얼굴과 같은 패턴을 나타냅니다.\n","\n","\n","  <img src='https://e2eml.school/images/cnn18.png'>\n"]},{"cell_type":"markdown","metadata":{"id":"mupehLizQOPT"},"source":["## Fully connected layers (Dense Layers)\n","\n","완전히 연결된 레이어는 높은 수준의 필터링된 이미지를 가져와서 투표로 변환합니다. <br>우리의 경우, 우리는 X와 O의 두 종류 중 하나만 결정하면 됩니다.\n","\n","  <img src='https://e2eml.school/images/cnn13.png'>\n","\n","새로운 이미지가 CNN에 제시되면 맨 마지막에 완전히 연결된 레이어에 도달할 때까지 하단 레이어를 통과합니다.<br> 그런 다음 선거가 열린다.\n","\n","그러나 이 과정이 완전히 민주적인 것은 아니다.<br> 어떤 값은 이미지가 X일 때 다른 값보다 훨씬 더 잘 알고, 어떤 값은 특히 이미지가 O일 때 잘 알고 있습니다.\n","\n","이 사람들은 다른 사람들보다 더 많은 표를 얻습니다.<br> 이러한 투표는 각 가치와 각 범주 사이의 가중치 또는 연관 강도로 표현됩니다.\n","\n","실제로 각 중간 레이어가 팬텀 \"숨겨진\" 카테고리에 투표하면서 완전히 연결된 여러 레이어가 함께 쌓이는 경우가 많습니다.\n","\n","실제로 각 추가 계층을 통해 네트워크는 보다 정교한 기능의 조합을 학습하여 보다 나은 의사결정을 내릴 수 있습니다.\n","\n","\n","  <img src='https://e2eml.school/images/cnn14.png'>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EQOSsqc-Q01L"},"source":["## Backpropagation\n","\n","우리의 이야기는 잘 채워지고 있지만, 여전히 큰 구멍이 있다.기능의 출처는 어디입니까?<br> 완전히 연결된 레이어의 중량은 어떻게 찾을 수 있을까요?<br>\n","\n","만약 이 모든 것이 손으로 선택되어야 한다면, CNN은 그들보다 훨씬 덜 인기가 있을 것이다.<br> 다행히도, 역전파라고 불리는 기계학습 마법을 우리에게도 효과가 있습니다.<br>\n","\n","\n","\n","모든 기능의 모든 픽셀과 완전히 연결된 모든 계층의 모든 무게가 임의의 값으로 설정되는 훈련되지 않은 CNN부터 시작합니다.<br> 그런 다음 차례로 이미지를 전송합니다.<br>\n","\n","\n","CNN이 처리하는 각각의 이미지는 투표 결과를 낳습니다.<br> 잘못된 투표의 양, 오류는 우리의 용모와 체중이 얼마나 좋은지를 말해줍니다.<br>\n","\n","\n","그런 다음 특징과 가중치를 조정하여 오차를 줄일 수 있습니다.<br> 각 값은 조금 더 높고 낮게 조정되며 매번 새 오차가 계산됩니다. <br>\n","\n","\n","오류를 줄일 수 있는 조정은 유지됩니다.<br>\n","\n","\n","모든 컨볼루션 레이어의 모든 피쳐 픽셀과 완전히 연결된 레이어의 모든 가중치에 대해 이 작업을 수행한 후 새로운 가중치가 해당 이미지에 대해 약간 더 잘 작동하는 답을 제공합니다. <br>\n","\n","\n","그런 다음 라벨이 지정된 영상 세트의 각 후속 영상에서 이 작업이 반복됩니다.<br>\n","\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"dGu9L8ZNRH0A"},"source":["## Hyperparameters\n","\n","불행하게도 CNN의 모든 측면을 그렇게 직설적으로 배울 수 있는 것은 아니다.<br> CNN 디자이너가 내려야 할 결정의 목록은 여전히 길다.<br>\n","각 Convolution 계층에 대해 몇 개의 기능이 있습니까?<br> 각 기능에 몇 개의 픽셀이 있습니까?<br>\n","각 풀링 도면층에 대해 창 크기를 선택하십시오. 무슨 보폭?<br>\n","완전히 연결된 각 층에 대해 숨겨진 뉴런은 몇 개입니까?<br>\n","이 외에도 다음과 같은 높은 수준의 아키텍처 의사 결정이 있습니다.<br> 각 레이어를 몇 개씩 포함할까요?<br>\n","<hr>"]},{"cell_type":"code","metadata":{"id":"TQt6k3T6RImK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630041711898,"user_tz":-540,"elapsed":5,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"77fab2c5-8ab5-4071-c643-8606da935c5b"},"source":["# Calculate O for the first covolutional layer(Conv2D) for our model\n","\n","''' \n","  kernel_size(K) = 3\n","  pool_size(P) = 2\n","  filters(N) = 64 \n","'''\n","# 파라미터 = 필터사이즈 * 필터사이즈 * 커널사이즈\n","\n","I = 28 # 원본사이즈 28 X 28\n","K= 3 # 커널사이즈 (kernel_size) 3 X 3\n","N = 64 # 필터의개수\n","S = 1 # 스트라이드\n","P = 0 #  패딩\n","\n","O = (I-K+2*P)/S +1 # [원본사이즈 - 필터사이즈 + (2 * 패딩) / 스트라이드] + 1\n","O"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26.0"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"kdHqEib-4Z_n"},"source":["##  AlexNet 모델구조\n","\n","네트워크의 텐서 사이즈와 파라미터의 갯수를 계산하는 공식에 대해 다루려 한다.\n","아래의 AlexNet을 이용하여 예시를 든다.\n","\n","<img src = 'https://seongkyun.github.io/assets/post_img/study/2019-01-25-num_of_parameters/fig1.png'>\n","\n","### AlexNet의 구조\n","\n","  - Input: 227* 227*3 크기의 컬러 이미지. \n","  - Conv-1: 11*11 크기의 커널 96개, stride=4, padding=0\n","  - MaxPool-1: stride 2, 3*3 max pooling layer\n","  - Conv-2: 5*5 크기의 커널 256개, stride=1, padding=2\n","  - MaxPool-2: stride 2, 3*3 max pooling layer\n","  - Conv-3: 3*3 크기의 커널 384개, stride=1, padding=1\n","  - Conv-4: 3*3 크기의 커널 384개, stride=1, padding=1\n","  - Conv-5: 3*3 크기의 커널 256개, stride=1, padding=1\n","  - Maxpool-3: stride 2, 3*3 max pooling layer (vecter의 갯수 6 X 6 X 256)\n","  - FC-1: 4096개의 fully connected layer (Dense layer의 갯수)\n","  - FC-2: 4096개의 fully connected layer\n","  - FC-3: 1000개의 fully connected layer\n","\n","__특징__\n","\n","- 비선형성을 추가하기 위해 Tanh 대신 relu 함수를 사용합니다. 동일한 정확도로 속도를 6배 향상시킵니다.\n","- 오버핏을 다루기 위해 정규화 대신 dropout을 사용합니다. 하지만 dropout이 0.5로 교육 시간은 두 배로 늘어남\n","- 네트워크 크기를 줄이기 위한 오버랩 풀링입니다. 상위 1개 오류율과 상위 5개 오류율을 각각 0.4%와 0.3% 감소시킨다.\n","\n","\n","\n","__AlexNet의 총 parameter 개수 및 출력 tensor size__\n","\n","  - AlexNet의 전체 parameter 수는 5개의 convolution layer와 3개의 FC layer에서 계산되는 parameter 개수들의 합\n","    - 62,378,344 개.\n","  - 자세한 parameter 및 tensor size는 아래 표 참조\n","\n","\n","  <img src ='https://seongkyun.github.io/assets/post_img/study/2019-01-25-num_of_parameters/fig2.png' width='500px' height='500px'>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9vlgzsZ94c29"},"source":["## Convolution layer의 output tensor\n","\n","각각 기호를 아래와 같이 정의\n","  - $O$: Size(width) of output image\n","  - $I$: Size(width) of input image\n","  - $K$: Size(width) of kernels used in the Conv layer\n","  - $N$: Number of kernels\n","  - $S$: Stride of the convolution operation\n","  - $P$: Padding size\n","\n","__$O$(width of output image)는 다음과 같이 계산__\n","\n","$$ O = \\frac{I-K+2P}{S}+1$$ \n","\n","  - 출력 이미지의 채널 수는 커널의 갯수($N$)와 같음\n","\n","__MaxPool layer의 output tensor size__\n","\n","각각 기호를 아래와 같이 정의\n","  - $O$: Size(width) of output image\n","  - $I$: Size(width) of input image\n","  - $S$: Stride of the convolution operation\n","  - $P_s$: Pooling size\n","\n","$$ O = \\frac{I-P_s}{S}+1$$ \n","\n","Convolution layer와는 다르게 출력의 채널 수는 입력의 개수와 동일  "]},{"cell_type":"markdown","metadata":{"id":"fGIyIKF46lNs"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"ouNHJxgk7QLO"},"source":["First Convolution Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSW02a0Y7SYY","executionInfo":{"status":"ok","timestamp":1630041712923,"user_tz":-540,"elapsed":2,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"fba4c6c8-4d36-43ef-cbd4-467c015e66ff"},"source":["# Alexnet 아키텍처의 첫 번째 컨볼루션 레이어에 대한 O 계산\n","I = 227 # INPUT사이즈\n","N = 96 # 커널의 개수\n","K = 11 # 커널사이즈\n","S = 4 # 스트라이드\n","P = 0 # 패딩수\n","\n","O = int((I-K+2*P)/S +1) # OUTPUT 사이즈\n","print('First Convolution Layer의 출력 이미지의 크기(width) =',int(O))\n","print('First Convolution Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["First Convolution Layer의 출력 이미지의 크기(width) = 55\n","First Convolution Layer의 출력 이미지의 shape = (55, 55, 96)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dJV1CUEW9uAj"},"source":["First Pooling Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmI5iQfe-YgQ","executionInfo":{"status":"ok","timestamp":1630041713256,"user_tz":-540,"elapsed":3,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"63d71413-c5d9-432e-a3aa-ce9a5d37e69b"},"source":["# Alexnet 아키텍처의 첫 번째 풀링 레이어에 대한 O 계산\n","I = O # input 사이즈\n","S = 2 # 스트라이드\n","P = 0 # 패딩 수\n","P_s = 3 # 풀링사이즈 3 X 3\n","\n","O = int((I-P_s)/S +1) # (원본사이즈 - 폴링사이즈) / 스트라이드 수 +1\n","print('Second Pooling Layer의 출력 이미지의 크기(width) =',int(O))\n","print('Second Pooling Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Second Pooling Layer의 출력 이미지의 크기(width) = 27\n","Second Pooling Layer의 출력 이미지의 shape = (27, 27, 96)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PcIEWkVd-9w1"},"source":["Second Convolution Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOBPifIc_ezp","executionInfo":{"status":"ok","timestamp":1630041713691,"user_tz":-540,"elapsed":4,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"eee812d2-67b0-4a46-b615-72f438b072a9"},"source":["# Calculate O for the second covolutional layer for Alexnet architectue\n","\n","I = O \n","K = 5\n","N = 256\n","S = 1\n","P = 2\n","\n","O = int((I-K+2*P)/S +1)\n","print('Second Conv Layer의 출력 이미지의 크기(width) =',int(O))\n","print('Second Conv Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Second Conv Layer의 출력 이미지의 크기(width) = 27\n","Second Conv Layer의 출력 이미지의 shape = (27, 27, 256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nXL0AK33_iji"},"source":["Second pooling Layer의 출력 이미지는 (27,27,256)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u9f53Ay5_nte","executionInfo":{"status":"ok","timestamp":1630041714051,"user_tz":-540,"elapsed":3,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"bed3756f-f645-4825-b988-7edc1e714abc"},"source":["# Calculate O for the second pooling layer for Alexnet architectue\n","I = O\n","S = 2\n","P = 0\n","P_s = 3\n","\n","O = int((I-P_s)/S +1)\n","print('Second Pooling Layer의 출력 이미지의 크기(width) =',int(O))\n","print('Second Pooling Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Second Pooling Layer의 출력 이미지의 크기(width) = 13\n","Second Pooling Layer의 출력 이미지의 shape = (13, 13, 256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8gSnplw6_ovH"},"source":["Third Conv Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NG_fo3xZ_qgD","executionInfo":{"status":"ok","timestamp":1630041714398,"user_tz":-540,"elapsed":5,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"f664a0ac-da94-4943-fd6e-0b76561f7f7d"},"source":["# Calculate O for the third conv layer for Alexnet architectue\n","I = O\n","K = 3\n","N = 384\n","S = 1\n","P = 1\n","\n","O = int((I-K+2*P)/S +1)\n","print('Third Conv Layer의 출력 이미지의 크기(width) =',int(O))\n","print('Third Conv Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Third Conv Layer의 출력 이미지의 크기(width) = 13\n","Third Conv Layer의 출력 이미지의 shape = (13, 13, 384)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6seVb0va_rOm"},"source":["The 4th Conv Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5PuwHwx_tev","executionInfo":{"status":"ok","timestamp":1630041714398,"user_tz":-540,"elapsed":4,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"5fe42442-2f52-415b-de0f-8c404f96fa2a"},"source":["# Calculate O for the 4th conv layer for Alexnet architectue\n","I = O\n","K = 3\n","N = 384\n","S = 1\n","P = 1\n","\n","O = int((I-K+2*P)/S +1)\n","print('4th Conv Layer의 출력 이미지의 크기(width) =',int(O))\n","print('4th Conv Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":55,"outputs":[{"output_type":"stream","text":["4th Conv Layer의 출력 이미지의 크기(width) = 13\n","4th Conv Layer의 출력 이미지의 shape = (13, 13, 384)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qtXM8e8G_ufn"},"source":["The 5th Conv Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCEpZs11_wQs","executionInfo":{"status":"ok","timestamp":1630041714721,"user_tz":-540,"elapsed":6,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"224bbd06-ea43-44ed-f56b-e735c922bcb0"},"source":["# Calculate O for the 5th conv layer for Alexnet architectue\n","I = O\n","K = 3\n","N = 256\n","S = 1\n","P = 1\n","\n","O = int((I-K+2*P)/S +1)\n","print('5th Conv Layer의 출력 이미지의 크기(width) =',int(O))\n","print('5th Conv Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":56,"outputs":[{"output_type":"stream","text":["5th Conv Layer의 출력 이미지의 크기(width) = 13\n","5th Conv Layer의 출력 이미지의 shape = (13, 13, 256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7ygO7Tqr_xHj"},"source":["The last Pooling Layer의 출력 이미지"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7lgqQD0_zxe","executionInfo":{"status":"ok","timestamp":1630041715079,"user_tz":-540,"elapsed":1,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"f3580177-21fa-4da7-f560-dd76fb844b8e"},"source":["# Calculate O for the last pooling layer for Alexnet architectue\n","I = O\n","S = 2\n","P = 0\n","P_s = 3\n","\n","O = int((I-P_s)/S +1)\n","print('Last Pooling Layer의 출력 이미지의 크기(width) =',int(O))\n","print('Last Pooling Layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Last Pooling Layer의 출력 이미지의 크기(width) = 6\n","Last Pooling Layer의 출력 이미지의 shape = (6, 6, 256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q8c1Qnee_08t"},"source":["## Convolution layer의 parameter\n","\n","  - CNN의 각 layer는 weight parameter와 bias parameter가 존재.\n","  - 전체 네트워크의 parameter 수는 각 conv layer 파라미터 수의 합\n","\n","각각 기호를 아래와 같이 정의\n","\n","  - $W_c$: Number of weights of the Conv layer\n","  - $B_c$: Number of biases of the Conv layer\n","  - $P_c$: Number of parameters of the Conv layer\n","  - $K$: Size(width) of kernels used in the Conv layer\n","  - $N$: Number of kernels\n","  - $C$: Number of channels of the input image\n","\n","  $$W_c = K^2 \\times C \\times N$$\n","  $$B_c = N$$\n","  $$P_c = W_c + B_c$$\n","\n","  - Conv layer에서 모든 커널의 깊이는 항상 입력 이미지의 채널 수와 같음\n","  - 따라서 모든 커널에는 $K^2\\times C$개의 parameter들이 있으며, 그러한 커널들이 $N$개 존재"]},{"cell_type":"markdown","metadata":{"id":"qrQK_LAP_4ax"},"source":["AlexNet의 Conv-1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBI8TXeWAkNd","executionInfo":{"status":"ok","timestamp":1630041715914,"user_tz":-540,"elapsed":5,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"d6cc13e9-2922-43b9-d68a-7c5760b1173c"},"source":["C = 3 # 이미지 채널의 수\n","K = 11 # 커널의 사이즈 11 X 11\n","N = 96 # 커널의 개수\n","\n","Wc = K**2*C*N # (커널사이즈 제곱) * 이미지채널의수 * 커널의 개수\n","Bc = N # biase == 커널의개수\n","Pc = Wc+Bc\n","\n","Wc, Bc, Pc"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34848, 96, 34944)"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"hhvQUBQDA3n7"},"source":["## Fully Connnected layer의 parameter"]},{"cell_type":"markdown","metadata":{"id":"YtdAvusMBrlB"},"source":["#### Case1: FC layer connected to a Conv layer\n","\n","각각의 기호를 아래와 같이 정의\n","  - $W_{cf}$: Number of weights of a FC layer which is connected to a Conv layer\n","  - $B_{cf}: Number of biases of a FC layer which is connected to a Conv layer\n","  - $P_{cf}: Number of parameters of a FC layer which is connected to a Conv layer\n","  - $O$: Size(width) of th output image of the previous Conv layer\n","  - $N$: Number of kernels in the previous Conv layer\n","  - $F$: Number of neurons in the FC Layer\n","\n","  $$W_{cf} = O^2 \\times N \\times F$$\n","  $$B_{cf} = F$$\n","  $$P_{cf} = W_{cf} + B_{cf}$$"]},{"cell_type":"markdown","metadata":{"id":"7bJKvzePBwiv"},"source":["#### Case2: FC layer connected to a FC Layer\n","각각의 기호를 아래와 같이 정의\n","  - $W_{ff}$: Number of weights of a FC layer which is connected to a FC layer\n","  - $B_{ff}$: Number of biases of a FC layer which is connected to a FC layer\n","  - $P_{ff}$: Number of parameters of a FC layer which is connected to a FC layer\n","  - $F$: Number of neurons in th FC layer\n","  - $F_{-1}$: Number of neurons in the previous FC layer\n","\n","  $$W_{ff} = F_{-1} \\times F$$\n","  $$B_{ff} = F$$\n","  $$P_{ff} = W_{ff} + B_{ff}$$\n","\n","\n","위의 식에서, $W_{ff} = F_{-1} \\times F$는 이전 FC layer의 neuron과 현재 FC layer의 neuron 사이의 총 연결 가중치의 개수.\n","Bias parameter의 개수는 뉴런의 개수()와 같음"]},{"cell_type":"markdown","metadata":{"id":"WXjC0CxNB3za"},"source":["<hr><br>\n","\n","Conv layer의 마지막단에 바로 붙는 FC"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ro36WDR5CE6O","executionInfo":{"status":"ok","timestamp":1630041717052,"user_tz":-540,"elapsed":4,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"ceb9aaf9-8e9d-41bf-c19e-5b7cac2df4ef"},"source":["O = 6\n","N = 256\n","F = 4096\n","\n","W_cf = O**2*N*F\n","B_cf = F\n","P_cf = W_cf+B_cf\n","\n","W_cf, B_cf, P_cf"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(37748736, 4096, 37752832)"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"28j9O0vGCHCR"},"source":["이 수는 모든 Conv layer의 pameter 갯수들보다 많은 수(그만큼 FC layer에는 많은 파라미터들이 필요)\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"9oVYSXKZCIgT"},"source":["마지막 FC layer인 FC-3"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OBLe4FkCKbO","executionInfo":{"status":"ok","timestamp":1630041717462,"user_tz":-540,"elapsed":3,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"741ee55a-3b99-4653-9ce5-bb3625f470c8"},"source":["F_1 = 4096\n","F = 1000\n","W_ff = F_1*F\n","B_ff = F\n","P_ff =W_ff+B_ff\n","\n","W_ff, B_ff, P_ff"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4096000, 1000, 4097000)"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"ympSWX44CSII"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"V_rZkwFFCT3F"},"source":["# **앞에서 살펴본 mnist CNN 모델에 대한 출력 shaped와 파라미터에 대해 알아보자**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qrFYTtwCeJG","executionInfo":{"status":"ok","timestamp":1630041717830,"user_tz":-540,"elapsed":6,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"6c873769-0976-4776-e86e-f411fd8c4464"},"source":["model.summary()"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 576)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 576)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 1154      \n","_________________________________________________________________\n","activation (Activation)      (None, 2)                 0         \n","=================================================================\n","Total params: 75,650\n","Trainable params: 75,650\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"451lCT4eCfgk","executionInfo":{"status":"ok","timestamp":1630041717831,"user_tz":-540,"elapsed":5,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"f87d2376-6eaa-4d76-c40c-5ad4ce67825e"},"source":["# Calculate O for the first covolutional layer for Our model\n","''' \n","  kernel_size(K) = 3\n","  pool_size(P_s) = 2\n","  filters(N) = 64\n","  padding(P) = 0\n","'''\n","\n","I=28\n","K= 3\n","N = 64\n","S = 1\n","# P = 0\n","\n","O = int((I-K+2*P)/S +1)\n","print('first Conv Layer의 출력 이미지의 크기(width) =',int(O))\n","print('first Conv Layer의 출력 이미지의 shape =',(O,O,N))\n","\n","C = 1\n","\n","Wc = K**2*C*N\n","Bc = N\n","Pc = Wc+Bc\n","\n","print('first Conv Layer의 파라미터 갯수 =',Pc)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["first Conv Layer의 출력 이미지의 크기(width) = 26\n","first Conv Layer의 출력 이미지의 shape = (26, 26, 64)\n","first Conv Layer의 파라미터 갯수 = 640\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-wRTDH4CkRQ","executionInfo":{"status":"ok","timestamp":1630041718229,"user_tz":-540,"elapsed":4,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"fc4860e5-68bf-4fa2-a893-1c353a3e6662"},"source":["# Calculate O for the first maxpooling layer for our model\n","\n","I = O\n","K = 3\n","N = 64\n","\n","# P = 0\n","P_s = 2\n","S = 2 # In Keras, stride가 선언되어 있지 않으면 디폴트 값은 Pool Size.\n","      # max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n","\n","O = int((I-P_s)/S +1)\n","print('the first maxpooling layer의 출력 이미지의 크기(width) =',int(O))\n","print('the first maxpooling layer의 출력 이미지의 shape =',(O,O,N))"],"execution_count":63,"outputs":[{"output_type":"stream","text":["the first maxpooling layer의 출력 이미지의 크기(width) = 13\n","the first maxpooling layer의 출력 이미지의 shape = (13, 13, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o0sPpvXXCmC-","executionInfo":{"status":"ok","timestamp":1630041719380,"user_tz":-540,"elapsed":2,"user":{"displayName":"[21_HF173]이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":[""],"execution_count":63,"outputs":[]}]}