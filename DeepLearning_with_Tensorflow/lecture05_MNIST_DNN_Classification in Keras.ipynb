{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lecture06_MNIST_DNN_Classification in Keras.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPyVmZuBqqENIEVbGo9B+sv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AJYRbWIOk-4Q"},"source":["# **Typical architecture of a classification neural network**\n","분류 신경망의 일반적인 구조"]},{"cell_type":"markdown","metadata":{"id":"wePf7sAn3pY5"},"source":["분류 신경망의 구조는 당신이 연구하고 있는 문제에 따라 매우 다양함\n","\n","* Input layer\n","* Hidden layers\n","* Oneput\n","\n","나머지는 대부분 데이터 분석가가 모델을 만드는 데 달려 있습니다.\n","\n","다음은 분류 신경망에서 자주 사용하는 몇 가지 표준 값입니다."]},{"cell_type":"markdown","metadata":{"id":"6d-9Ma_y5I9U"},"source":["\n","| **Hyperparameter** | **Binary Classification** | **Multiclass classification** |\n","| --- | --- | --- |\n","| Input layer shape | Same as number of features (e.g. 5 for age, sex, height, weight, smoking status in heart disease prediction) | Same as binary classification |\n","| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited | Same as binary classification |\n","| Neurons per hidden layer | Problem specific, generally 10 to 100 | Same as binary classification |\n","| Output layer shape | 1 (one class or the other) | 1 per class (e.g. 3 for food, person or dog photo) |\n","| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) | Same as binary classification |\n","| Output activation | [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) | [Softmax](https://en.wikipedia.org/wiki/Softmax_function) |\n","| Loss function | [Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) ([`tf.keras.losses.BinaryCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) in TensorFlow) | Cross entropy ([`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in TensorFlow) |\n","| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) | Same as binary classification |\n"]},{"cell_type":"markdown","metadata":{"id":"vqyazJks57t0"},"source":["# **Prerequisite Python Modules**"]},{"cell_type":"markdown","metadata":{"id":"uW12UeDt7Ie7"},"source":["먼저 일부 소프트웨어를 Python 환경에 로드"]},{"cell_type":"code","metadata":{"id":"GVguZZBL6Atx"},"source":["import tensorflow as tf\n","import numpy as np                   # advanced math library\n","import matplotlib.pyplot as plt      # MATLAB like plotting routines\n","import random                        # for generating random numbers\n","\n","from tensorflow.keras.models import Sequential  # Model type to be used\n","from tensorflow.keras.layers import Dense, InputLayer, Flatten, Dropout, Activation\n","from tensorflow.keras.datasets import mnist     # MNIST dataset is included in Keras\n","from tensorflow.keras.utils import to_categorical, plot_model\n","\n","print(tf.__version__) # find the version number (should be 2.x+)\n","\n","# 그래픽카드 유무 확인 및 메모리 확장 설정\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  print('사용가능한 GPU 갯수: ',len(gpus), '\\n')\n","      \n","  try:\n","    # 프로그램이 실행되어 더 많은 GPU 메모리가 필요하면, 텐서플로 프로세스에 할당된 GPU 메모리 \n","    # 영역을 확장할 수있도록 허용\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","\n","  except RuntimeError as e:\n","    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n","    print(e)\n","\n","# 설치된 GPU 상세내용 확인\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0SpeDOPD5jjM"},"source":["# **Loading Training Data**"]},{"cell_type":"markdown","metadata":{"id":"a0pVQpxq7goN"},"source":["MNIST 데이터셋은 Keras 내에서 편리하게 번들로 제공되며 Python에서 일부 기능을 쉽게 분석할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"_ItSU_Ta5qya"},"source":["# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfxaCKi450N8"},"source":["X_train = X_train.reshape(60000, 784) # reshape 60,000 28 x 28 matrices into 60,000 784-length vectors.\n","X_test = X_test.reshape(10000, 784)   # reshape 10,000 28 x 28 matrices into 10,000 784-length vectors.\n","\n","X_train = X_train.astype('float32')   # change integers to 32-bit floating point numbers\n","X_test = X_test.astype('float32')\n","print\n","X_train /= 255                        # normalize each value for each pixel for the entire vector for each input\n","X_test /= 255\n","\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ix54ykPq7xrl"},"source":["클래스(고유 숫자)를 원핫 형식으로 수정\n","\n","```\n","0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n","2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n","etc.\n","```\n","\n","만약 우리 네트워크의 최종 산출물이 이 클래스들 중 하나에 매우 가깝다면, 아마도 다음 예와 같음:\n","\n","```\n","[0, 0.94, 0, 0, 0, 0, 0.06, 0, 0, 0]\n","```\n","그러면 이미지가 숫자 1의 이미지일 가능성이 가장 높습니다."]},{"cell_type":"code","metadata":{"id":"E5A0AHh274vW"},"source":["X_test[0]\n","nb_classes = 10 # number of unique digits\n","\n","Y_train = to_categorical(y_train,nb_classes)\n","Y_test = to_categorical(y_test,nb_classes)\n","print(X_test[0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lrqdFp2M8Ne4"},"source":["# **Building a 3-layer fully connected network (FCN)**\n","3계층 완전 연결 네트워크(FCN) 구축\n","\n","<img src=\"https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/figure.png?raw=1\" />"]},{"cell_type":"markdown","metadata":{"id":"KTcFqG_X9CYw"},"source":["# **DNN Model**"]},{"cell_type":"code","metadata":{"id":"3KzN2iuX9Ibd"},"source":["# 순차 모델은 레이어의 선형 스택이며 매우 일반적입니다.\n","\n","model = Sequential()\n","\n","# 첫 번째 숨겨진 층은 512개의 노드 세트입니다(인공 뉴런).\n","# 각 노드는 각 입력 벡터로부터 요소를 수신하고 일부 가중치와 편향을 적용합니다.\n","model.add(Dense(512, input_shape=(784,)))\n","model.add(Activation('relu')) # Rerectified Linear Unit(ReLU)는 모든 음의 입력을 0으로 변환\n","                              # 노드의 양수값은 변경되지 않음\n","\n","model.add(Dropout(0.2)) # 과적합을 방지하기 위해 20%노드를 비활성화\n","\n","# 두 번째 숨겨진 레이어는 첫 번째 레이어와 동일하게 나타납니다.\n","# 그러나, 각각의 512 노드가 입력 이미지 데이터로부터 784개의 입력을 수신하는 대신,\n","# 첫 번째 512 노드 레이어의 출력에서 512개의 입력을 수신합니다.\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","\n","# 10개의 뉴런으로 구성된 최종 레이어는 이전 512-노드 레이어에 완전히 연결됩니다.\n","# FCN의 최종 레이어는 원하는 클래스 수와 같아야 합니다(이 경우 10).\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","# \"softmax\" 활성함수는 가능한 n가지 결과에 대한 확률 분포를 나타냅니다.\n","# 값은 모두 음수가 아니며 합은 1입니다.\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bc-yW1yc-GVO"},"source":["# **Compiling the model**"]},{"cell_type":"markdown","metadata":{"id":"-GbI5rPo_FKA"},"source":["* Keras는 Theano와 TensorFlow 위에 구축되어 있음. 두 패키지 모두 Python에서 계산 그래프를 정의할 수 있음<br> \n","* 그러면 Python 인터프리터의 오버헤드 없이 CPU 또는 GPU에서 효율적으로 컴파일되고 실행됩니다.<br>\n","\n","* 모형을 컴파일할 때 Keras는 손실 함수와 최적기를 지정하도록 요청합니다.<br> \n","* 여기서 사용할 손실 함수를 범주형 교차 엔트로피라고 하며, 두 확률 분포를 비교하는 데 적합한 손실 함수입니다.<br>\n","\n","* 우리의 예측은 10개의 다른 자릿수에 대한 확률 분포(예: \"이 이미지가 3, 10% 확실합니다. 8, 5% 확실합니다.\"). <br>\n","* 목표는 정확한 범주의 확률 분포이고 그 밖의 모든 범주의 확률 분포는 0입니다.\n","* 교차 엔트로피는 예측 분포가 목표 분포와 얼마나 다른지를 나타내는 측도입니다.<br>\n","\n","* 옵티마이저는 모델이 경사하강을 통해 얼마나 빨리 학습하는지 결정하는 데 도움이 됩니다. \n","* 내려가는 속도를 학습 속도라고 합니다.<br>"]},{"cell_type":"markdown","metadata":{"id":"mEq8mckX_YCa"},"source":["<img src = \"https://randlow.github.io/images/ml/gradient-descent.png\" >"]},{"cell_type":"markdown","metadata":{"id":"0WYgng9g_5Ms"},"source":["<img src = \"https://srdas.github.io/DLBook/DL_images/TNN2.png\" >"]},{"cell_type":"markdown","metadata":{"id":"M_QSiiG5_9RJ"},"source":["그러면 학습률이 작을수록 더 나을까요? 그렇지 않아!<br> 옵티마이저는 손실 함수의 글로벌 최소값을 무시한 채 로컬 최소값에 고착되지 않는 것이 중요합니다.<br> 때때로 그것은 지역 최소치에서 벗어나기 위해 더 큰 학습률을 시도한다는 것을 의미합니다."]},{"cell_type":"markdown","metadata":{"id":"uK4ySgzzAFQr"},"source":["<img src = 'https://miro.medium.com/max/2060/1*9DVEXY4X0eNAx_ZHoD_PPA.png' >"]},{"cell_type":"code","metadata":{"id":"IGL_jO2YAHbR"},"source":["# Adam Optimizer를 학습에 사용\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdubpgl3ANN9"},"source":["# **Train the model**"]},{"cell_type":"markdown","metadata":{"id":"5SWYBFQfARuv"},"source":["배치 크기는 손실 함수, 기울기 및 후방 전파를 계산하는 데 사용되는 단계당 데이터 양을 결정합니다. <br>배치 크기가 크면 네트워크에서 교육을 더 빨리 완료할 수 있습니다. 그러나 교육 속도 이외에 고려해야 할 다른 요소도 있습니다."]},{"cell_type":"markdown","metadata":{"id":"ioR3FNsoAVaT"},"source":["배치 크기가 너무 크면 손실 함수의 로컬 최소값이 평활화되어 글로벌 최소값을 찾은 것으로 생각되어 최적화 프로그램이 한 개로 안착됨"]},{"cell_type":"markdown","metadata":{"id":"FatsTwt3Abz9"},"source":["배치 크기가 너무 작으면 노이즈가 매우 많은 손실 함수가 생성되고 최적화 프로그램이 전역 최소값을 찾지 못할 수 있음"]},{"cell_type":"markdown","metadata":{"id":"bdTuDg4CAhEz"},"source":["따라서 배치 크기가 적절하면 시행착오를 겪어야 찾을 수 있습니다."]},{"cell_type":"code","metadata":{"id":"JvOKx4D5ArYl"},"source":["import time\n","start = time.time()\n","history = model.fit(X_train, Y_train, batch_size = 128, epochs = 5,\n","                    validation_data = (X_test, Y_test), verbose = 1)\n","end = time.time()\n","print('Execution time in seconds = ', end-start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOBnZcZOBHJf"},"source":["import pandas as pd\n","pd.DataFrame(history.history).plot(title=\"Loss and Accuracy\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wM-QCxfgBw-P"},"source":["순서대로 두 숫자는 교육 세트의 네트워크 손실 함수 값과 교육 데이터에 대한 네트워크의 전반적인 정확도를 나타냅니다.<br> 하지만 훈련하지 않은 데이터는 어떻게 되나요?"]},{"cell_type":"markdown","metadata":{"id":"qPMssZ2RCHqa"},"source":["# **Check the accuracy for test data.**"]},{"cell_type":"code","metadata":{"id":"idC5zA-OCO5m"},"source":["loss, accuracy = model.evaluate(X_test, Y_test)\n","print('Test score:', loss)\n","print('Test accuracy:', accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTtcXk2uCP9I"},"source":["# **Evaluate Model's Accuracy on Test Data**\n","테스트 데이터에 대한 모형의 정확도 평가"]},{"cell_type":"markdown","metadata":{"id":"k0tWaCjhCZtS"},"source":["# **분류성능평가지표 - 혼동행렬(Confusion Matrix)**\n","모델을 평가하는 요소는 결국, 모델이 내놓은 답과 실제 정답의 관계로써 정의를 내릴 수 있습니다.<br> 정답이 True와 False로 나누어져있고, 분류 모델 또한 True False의 답을 내놓습니다.<br> 그렇게 하면, 이진분류(Binary Classification)의 경우 아래와 같이 2x2 matrix로 case를 나누어볼 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"O8NOe8YeCfOn"},"source":["img src=\"https://t1.daumcdn.net/cfile/tistory/99DC064C5BE056CE10\">\n","\n","위와 같이 구분한 표를 혼동행렬(Confusion Matrix)이라고 합니다\n","```\n","  - True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)\n","  - False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)\n","  - False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)\n","  - True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)\n","```\n","    - 거짓 긍정(FP): 우리는 그렇다고 예측했지만, 실제로는 질병 가지지않음\n","    - 거짓 부정(FN): 우리는 아니라고 예상했지만, 실제로는 질병을 가짐\n","    - 참 긍정(TP): 우리는 그렇다고 예측했고, 실제로도 질병을 가짐\n","    - 참 부정(TN): 우리는 아니라고 예상했고, 실제로도 질병을 가지지 않음"]},{"cell_type":"markdown","metadata":{"id":"m3AgER-nEQMN"},"source":[" <hr>"]},{"cell_type":"markdown","metadata":{"id":"ZsJrglePCmAj"},"source":["# **분류성능평가지표 - Precision(정밀도)과 Recall(재현율)**\n","\n","  - Precision(정밀도): 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율\n","\n","    $$Precision =  \\frac {TP}{TP+FP}$$\n","\n","  - Recall(재현율): 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율\n","\n","    $$Recall =  \\frac {TP}{TP+FN}$$\n","\n","    통계학에서는 sensitivity로, 그리고 다른 분야에서는 hit rate라는 용어로도 사용합니다. 실제 날씨가 맑은 날 중에서 모델이 맑다고 예측한 비율을 나타낸 지표인데, 정밀도(Precision)와 True Positive의 경우를 다르게 바라보는 것입니다. 즉, Precision이나 Recall은 모두 실제 True인 정답을 모델이 True라고 예측한 경우에 관심이 있으나, 바라보고자 하는 관점만 다릅니다. Precision은 모델의 입장에서, 그리고 Recall은 실제 정답(data)의 입장에서 정답을 정답이라고 맞춘 경우를 바라보고 있습니다. \n","\n","      <img src= \"https://t1.daumcdn.net/cfile/tistory/999D9C465BE116E43C\">\n","\n","  A는 실제 날씨가 맑은 날입니다. 그리고 B는 모델에서 날씨가 맑은 날이라고 예측한 것입니다.\n","  $$Precison =\\frac{b}{b+c},  \\hspace{2ex}  Recall = \\frac{b}{a+b}$$\n","\n","  모델의 입장에서 모두 맑은 날이라고만 예측하는 경우를 생각해봅시다. 그렇게 되면 TN(d)의 영역이 줄어들게 되고 그에 따라 FN(a)의 영역 또한 줄게 됩니다. 그러므로 Recall은 분모의 일부인 FN(a)영역이 줄기 때문에 Recall은 100%가 됩니다. \n","\n","    <img src = \"https://t1.daumcdn.net/cfile/tistory/9951F44B5BE1205F1E\">\n","\n","  위 그림의 왼쪽 Case에서 Recall은 20 / 50 = 40%, Precision = 20 / 60 = 33.3% 입니다. 그리고 분류모델이 모두 True라고 예측한 오른쪽의 case에서의 recall은 FN = 0이므로 100%이지만 그에 따라 FP가 늘어서 precision은 20/100 = 20%가 되었습니다. 이처럼 precision과 recall은 모두 높은 것이 좋지만, trade-off 관계에 있어서 함께 늘리기가 힘듭니다.\n","\n"," Precision과 Recall은 trade-off관계이며 상호보완적으로 해석해야하며, 두 지표가 모두 높을 수록 좋은 모델입니다.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LRKd_qpJENKc"},"source":[" <hr>"]},{"cell_type":"markdown","metadata":{"id":"MKkAECPGDwvZ"},"source":["## **분류성능평가지표 - Accuracy(정확도) 와 F1 Score**\n","\n","  - Accuracy(정확도)\n","\n","  $$Accuracy(정확도) = \\frac {TP + TN}{TP+FN+FP+FN}$$\n","\n","  앞서 설명한 두 지표는 모두 True를 True라고 옳게 예측한 경우에 대해서만 다루었습니다. 하지만, False를 False라고 예측한 경우도 옳은 경우입니다. 이때, 해당 경우를 고려하는 지표가 바로 정확도(Accuracy)입니다. \n","\n","  정확도는 **가장 직관적으로 모델의 성능을 나타낼 수 있는 평가 지표**입니다. \n","  \n","  하지만, 여기서 고려해야하는 것이 있습니다. 바로 domain의 편중(bias)입니다. 만약 우리가 예측하고자 하는 한달 동안이 특정 기후에 부합하여 비오는 날이 흔치 않다고 생각해보죠. 이 경우에는 해당 data의 domain이 불균형하게되므로 맑은 것을 예측하는 성능은 높지만, 비가 오는 것을 예측하는 성능은 매우 낮을 수 밖에 없습니다. 따라서 이를 보완할 지표가 필요합니다.\n","\n","  - F1 Score: Precision과 Recall의 [조화평균(역수의 산술 평균의 역수)](https://ko.wikipedia.org/wiki/%EC%A1%B0%ED%99%94_%ED%8F%89%EA%B7%A0)입니다. \n","\n"," $$F1  = 2 \\times \\frac {1}{\\frac{1}{Precision} + \\frac{1}{recall}}  = 2 \\times \\frac{Precision \\times Recall}{Precision+Recall}$$ \n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q8cli0ObEI6A"},"source":["\n","\n","| **Metric name/Evaluation method** | **Defintion** | **Code** |\n","| --- | --- | --- |\n","| Accuracy | Out of 100 predictions, how many does your model get correct? E.g. 95% accuracy means it gets 95/100 predictions correct. | [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) or [`tf.keras.metrics.Accuracy()`](tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy) |\n","| Precision | Proportion of true positives over total number of samples. Higher precision leads to less false positives (model predicts 1 when it should've been 0). | [`sklearn.metrics.precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) or [`tf.keras.metrics.Precision()`](tensorflow.org/api_docs/python/tf/keras/metrics/Precision) |\n","| Recall | Proportion of true positives over total number of true positives and false negatives (model predicts 0 when it should've been 1). Higher recall leads to less false negatives. | [`sklearn.metrics.recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) or [`tf.keras.metrics.Recall()`](tensorflow.org/api_docs/python/tf/keras/metrics/Recall) |\n","| F1-score | Combines precision and recall into one metric. 1 is best, 0 is worst. | [`sklearn.metrics.f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) |\n","| [Confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)  | Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagnol line). | Custom function or [`sklearn.metrics.plot_confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) |\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PHDa2HboEUhP"},"source":["컴파일할 때 측정 지표 매개변수에 \"\"정확성\"을 전달했으므로, 이 매개변수에 대해 평가()를 호출하면 손실과 정확성뿐만 아니라 손실도 반환"]},{"cell_type":"code","metadata":{"id":"T9Wrqo4EEZyd"},"source":["# Note: The following confusion matrix code is a remix of Scikit-Learn's \n","# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n","# and Made with ML's introductory notebook - https://github.com/madewithml/basics/blob/master/notebooks/09_Multilayer_Perceptrons/09_TF_Multilayer_Perceptrons.ipynb\n","import itertools\n","from sklearn.metrics import confusion_matrix\n","\n","# Our function needs a different name to sklearn's plot_confusion_matrix\n","def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15): \n","  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n","\n","  If classes is passed, confusion matrix will be labelled, if not, integer class values\n","  will be used.\n","\n","  Args:\n","    y_true: Array of truth labels (must be same shape as y_pred).\n","    y_pred: Array of predicted labels (must be same shape as y_true).\n","    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n","    figsize: Size of output figure (default=(10, 10)).\n","    text_size: Size of output figure text (default=15).\n","  \n","  Returns:\n","    A labelled confusion matrix plot comparing y_true and y_pred.\n","\n","  Example usage:\n","    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n","                          y_pred=y_preds, # predicted labels\n","                          classes=class_names, # array of class label names\n","                          figsize=(15, 15),\n","                          text_size=10)\n","  \"\"\"  \n","  # Create the confustion matrix\n","  cm = confusion_matrix(y_true, y_pred)\n","  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n","  n_classes = cm.shape[0] # find the number of classes we're dealing with\n","\n","  # Plot the figure and make it pretty\n","  fig, ax = plt.subplots(figsize=figsize)\n","  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n","  fig.colorbar(cax)\n","\n","  # Are there a list of classes?\n","  if classes:\n","    labels = classes\n","  else:\n","    labels = np.arange(cm.shape[0])\n","  \n","  # Label the axes\n","  ax.set(title=\"Confusion Matrix\",\n","         xlabel=\"Predicted label\",\n","         ylabel=\"True label\",\n","         xticks=np.arange(n_classes), # create enough axis slots for each class\n","         yticks=np.arange(n_classes), \n","         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n","         yticklabels=labels)\n","  \n","  # Make x-axis labels appear on bottom\n","  ax.xaxis.set_label_position(\"bottom\")\n","  ax.xaxis.tick_bottom()\n","\n","  # Set the threshold for different colors\n","  threshold = (cm.max() + cm.min()) / 2.\n","\n","  # Plot the text on each cell\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n","             horizontalalignment=\"center\",\n","             color=\"white\" if cm[i, j] > threshold else \"black\",\n","             size=text_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyxkz4B4EfzS"},"source":["# Get predicted class for X_test by converting all of the predictions from probabilities to labels\n","# 모든 예측을 확률에서 레이블로 변환하여 X_test의 예측 클래스를 가져옵니다.\n","y_probs = model.predict(X_test)\n","#print(tf.argmax(pred[0:10]))\n","print(y_probs[0:10])\n","\n","y_pred=y_probs.argmax(axis=1)\n","print(y_pred[0:10])\n","print(y_test[0:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCNqArMRErUS"},"source":["# 검증되지 않은 혼돈 행렬 확인\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_true=y_test, \n","                 y_pred=y_pred)\n","df_cm = pd.DataFrame(cm)\n","df_cm['sum']=df_cm.sum(axis=1)\n","df_cm.loc['Total']= df_cm.sum()\n","df_cm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEkqNoUqE1yS"},"source":["그 혼돈 매트릭스는 이해하기 어려우니, 전에 만든 기능을 사용해서 더 예쁘게 만듬"]},{"cell_type":"code","metadata":{"id":"PTIALSzKE999"},"source":["# Make a prettier confusion matrix\n","\n","class_names=[str(i) for i in range(0,10)]\n","make_confusion_matrix(y_true=y_test, \n","                      y_pred=y_pred,\n","                      classes=class_names,\n","                      figsize=(15, 15),\n","                      text_size=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rFRLEGJNE_HV"},"source":["# **Precision, Recall, and F1-score**\n","정밀도, 리콜 및 F1-점수"]},{"cell_type":"code","metadata":{"id":"dQrKD1psFEEc"},"source":["# Let's consider the classification results for digit '1',\n","\n","TP  = df_cm.iat[0,0]\n","FN = df_cm.iat[0, 10]-TP\n","FP = df_cm.iat[10, 0]-TP\n","\n","precision = TP/(TP +FP)\n","recall = TP/(TP +FN)\n","F1 = 2*(precision*recall)/(precision+recall)\n","\n","print(\"True Positive = {},  False Negative =  {},  False Positive = {}\".format(TP,FN,FP))\n","print(\"\\nPrecision = {:.4f},  Recall =  {:.4f},  F1 Score = {:.4f}\".format(precision,recall,F1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gXIJfD3FLDw"},"source":["# Use sklearn classification_report.\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred, digits=4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0R98h5MBFMVM"},"source":["# **Inspecting the output**\n","출력 검사"]},{"cell_type":"markdown","metadata":{"id":"_QdxSdSxFRgn"},"source":["출력을 검사하고 모든 것이 정상으로 보이는지 확인하는 것은 항상 좋은 생각입니다. 여기서는 정답과 정답이 틀린 예를 살펴보겠습니다."]},{"cell_type":"code","metadata":{"id":"bqDvllcVFUV6"},"source":["# predict_classes 함수는 가장 높은 확률 클래스를 출력합니다.\n","# 각 입력 예제에 대해 훈련된 분류자에 따라\n","# predicted_classes = model.predict_classes(X_test)\n","\n","# 어떤 항목이 맞았는지/틀렸는지 확인\n","correct_indices = np.nonzero(predicted_classes == y_test)[0]\n","\n","incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n","\n","\n","incorrect_indices.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rIVf1FfgFVgt"},"source":["# **Visualize FN**\n","FN 시각화"]},{"cell_type":"code","metadata":{"id":"zpsz1dZFGIms"},"source":["# 앞서데이터 전처리과정에서에서 우리는 28 by 28 이차원 이미지데이터 1차원 벡터로 Reshape 시켜놓았다. \n","# 이미지 플로팅을 위해 우리는 다시 이미지를 이차원으로 변화 시킨다.\n","\n","x_test = X_test.reshape(10000, 28,28) \n","\\"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFSCT8mLGJxd"},"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Plot FN classified images\n","\n","def show_FN(x_test,y_test, y_pred, true_class):\n","\n","  dict = {'True Class': y_test,'Predicted Class':y_pred}\n","  df = pd.DataFrame(dict)\n","  df['row_num'] = df.index\n","  df = df[df['True Class']==true_class]\n","  df = df[df['True Class'] != df['Predicted Class']]\n","  n = df.shape[0] # sample size\n","  print(\"Total Rows = \",n)\n","  print(df)\n","\n","  fig = plt.figure(figsize=(10, 20))\n","\n","  cols = 5\n","  rows = int(n/cols) +1\n","\n","  for i in range(n):\n","    ax = plt.subplot(rows, cols, i+1)\n","    plt.imshow(x_test[df.iat[i,2]], cmap='gray')\n","    plt.title(\"True: {} Pred: {} \".format(df.iat[i,0],df.iat[i,1]))\n","    plt.axis(False)\n","\n","show_FN(x_test,y_test, y_pred, 1)  # Check for 2, 8, 9"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRlZMvrkGL1p"},"source":["# **Visualize FP**"]},{"cell_type":"code","metadata":{"id":"cpRZ4qG9GVMO"},"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import math\n","\n","# Plot FP classified images\n","\n","def show_FP(x_test,y_test, y_pred, pred_class):\n","\n","  dict = {'True Class': y_test,'Predicted Class':y_pred}\n","  df = pd.DataFrame(dict)\n","  df['row_num'] = df.index\n","  df = df[df['Predicted Class']==pred_class]\n","  df = df[df['True Class'] != df['Predicted Class']]\n","  n = df.shape[0] # sample size\n","  print(\"Total Rows = \",n)\n","  print(df)\n","\n","  fig = plt.figure(figsize=(10, 20))\n","\n","  cols = 5\n","  rows = int(n/cols) +1\n","\n","  for i in range(n):\n","    ax = plt.subplot(rows, cols, i+1)\n","    plt.imshow(x_test[df.iat[i,2]], cmap='gray')\n","    plt.title(\"Pred {} True: {} \".format(df.iat[i,1],df.iat[i,0]))\n","    plt.axis(False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aG3-eLiGVg_"},"source":["show_FP(x_test,y_test, y_pred, 3) # Check for cases predicted as 3 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-qAswUSGWf_"},"source":["show_FP(x_test,y_test, y_pred, 7)"],"execution_count":null,"outputs":[]}]}