{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"learning_project01.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOCnS7MZoWKGG4VW7SdgCxt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jaB6Xwj4iSsa"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsOex4PAix1E"},"source":["!ls /content/drive/MyDrive/data/gpascore.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2FeXbFbujrpf"},"source":["# 키와 신발사이즈로 간단한 머신러닝 학습"]},{"cell_type":"code","metadata":{"id":"dSVUIWAfjFzW"},"source":["import tensorflow as tf\n","\n","키 = 170\n","신발 = 260\n","# 신발 = 키 * a + b\n","\n","# W(weight)를 저장하고 싶으면 Variable 만들어야함\n","# Variable은 변수\n","a = tf.Variable(0.1) # 초기값 설정 (W값 만드는 문법)\n","b = tf.Variable(0.2)\n","\n","# 손실함수\n","def 손실함수():\n","    예측값 =  키 * a + b\n","    return tf.square(260 - 예측값) # 실제값 - 예측값의 차이 (오차)\n","\n","# 경사하강법으로 w값이 업데이트됨\n","opt = tf.keras.optimizers.Adam(learning_rate=0.1) # Adam이라는 경우에따라서 업데이트해주는 optimizers\n","\n","for i in range(300):\n","    opt.minimize(손실함수, var_list= [a,b])\n","\n","# a, b의 가중치 업데이트 됨\n","print(a.numpy(), b.numpy())\n","\n","입력키 = 170\n","print(입력키 * a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oA3pAHJhjlB3"},"source":["# 대학원 합격예측 머신러닝 학습"]},{"cell_type":"code","metadata":{"id":"mzmoj2nTnOJo"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","#### 딥러닝 모델 디자인하기\n","\n","# csv 파일 읽기 (데이터프레임)\n","data = pd.read_csv('/content/drive/MyDrive/data/gpascore.csv')\n","# print(data)\n","\n","## 데이터 전처리\n","\n","# 빈칸이 몇개인지 확인\n","# print(data.isnull().sum())\n","\n","# 빈칸이 있는 행 제거 \n","data = data.dropna()\n","\n","# y데이터 정렬 (data안의 admit열 출력)\n","y데이터 = data['admit'].values\n","\n","# x데이터 정렬\n","x데이터 = []\n","# iterrows는 데이터프레임을 가로 한줄씩 출력가능\n","# i는 행번호, rows는 데이터\n","for i, rows in data.iterrows():\n","    # data안의 gre, gpa, rank열 list에 저장\n","    x데이터.append( [ rows['gre'],rows['gpa'],rows['rank'] ])\n","\n","# 빈값에 원하는 숫자 채우기\n","# data.fillna(100)\n","\n","# 원하는 속성의 열 출력\n","# print('gpa : ',data['gpa'])\n","# print('min : ',data['gpa'].min())\n","# print('max : ',data['gpa'].max())\n","# print('count : ',data['gpa'].count())\n","# print('mean : ',data['gpa'].mean())\n","\n","# 딥러닝 모델\n","model = tf.keras.models.Sequential([ \n","    tf.keras.layers.Dense(64, activation='tanh'), # hidden layer의 갯수 (64개)\n","    tf.keras.layers.Dense(128, activation='tanh'), # hidden layer의 갯수 (128개)\n","    tf.keras.layers.Dense(1, activation='sigmoid') # 마지막 출력값, 예측결과는 0~1사이 (sigmoid사용)\n","])\n","\n","# w값을 업데이트해주는 optimizer Adam\n","# 0인지 1인지 분류할때 사용하는 binary_crossentropy\n","# 딥러닝을 평가하는 metrics = ['accuracy']\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# model 학습 시키기\n","# 학습횟수는 epochs에 지정\n","# x데이터는 정답예측에 필요한 인풋, y데이터는 정답\n","# 데이터는 numpy.array타입으로 넣어야함\n","model.fit( np.array(x데이터), np.array(y데이터), epochs=1000)\n","# ex\n","# x데이터 : [ [380, 3.21, 3], [660, 3.67, 3], [], [] ...]\n","# y데이터 : [0, 1, 1, 1, 0 ...]\n","\n","####################################################################\n","# 예측\n","예측값 = model.predict( [ [750, 3.70, 3], [400, 2.2, 1] ] )\n","print(예측값)"],"execution_count":null,"outputs":[]}]}