{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lecture03_Regression in Tensorflow.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN9dKg6wjmAx6LdiULWZqIc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RH7oeCLR5JID"},"source":["# OLS(Ordinary Least Squares) Model in Statistics\n","\\begin{equation}  y_{i}=\\beta_{0}+\\beta_{1}x_{i,1}+\\beta_{2}x_{i,2}+\\ldots+\\beta_{k}x_{i,k}+\\epsilon_{i} \\qquad \\text {for } i = 1,2,\\cdots,n \\end{equation}\n","<br>\n","또는 행렬식으로 표현하면,\n","\n","$$ y = X\\beta + \\epsilon $$\n","<br>\n","$$ X_{n * p} = \n","\\begin{bmatrix} \n","1 & x_{1,1} & x_{1,2} &\\cdots & x_{1,k} \\\\\n","1 & x_{2,1} & x_{2,2} &\\cdots & x_{2,k} \\\\\n"," \\vdots & \\vdots  & \\vdots  &\\vdots & \\vdots  \\\\\n","1 & x_{n,1} & x_{n,2} &\\cdots & x_{n,k} \\\\\n","\\end{bmatrix}\n","\\quad\n","$$\n","<br>\n","<br>\n","$$ y_{n * 1} = \n","\\begin{bmatrix} \n","y_{1} & \\\\\n","y_{2} & \\\\\n"," \\vdots & \\\\\n","y_n \\\\\n","\\end{bmatrix},\n","\\quad\n","%%%\n","\\beta_{p*1}=\n","\\begin{bmatrix} \n","\\beta_0 & \\\\\n","\\beta_1 & \\\\\n"," \\vdots & \\\\\n","\\beta_k \\\\\n","\\end{bmatrix} \n","$$\n","<br>\n","  - X: n개의 표본에서 얻은 $k$개의 독립변수에 대한 데이터 행렬\n","  - y: n개의 표본에서 얻은 종속변수(Dependent, presponse, or target Variable) 에 대한 데이터 백터\n","  - $\\epsilon$ 은 미지의 에러항\n","  - n: sample size\n","  - k: 독립변수(Independent, Explanatory, or predictor variables)의 갯수\n","  - $p = k+1$ : regression parameters의 갯수 ($\\beta_0, \\beta_1, \\beta_2, \\cdots, \\beta_k)$ \n","  - $\\epsilon_i$는 독립항등 정규분포(independently and identically normally distributed)를 가정  \n","  $$ \\epsilon_i \\sim \\mathcal{N}(0,\\,\\sigma^{2})$$\n","  - $\\beta_0$ 항은 $x_{i,0} =1$ 이 곱해진 것으로 간주할 수 있다.\n","<br>\n","\n","  OLS에서 $\\beta$는 아래 공식으로 구할 수있다.\n","\n","$$ \\hat{\\beta} = \\big(X'X)^{-1}X'y$$"]},{"cell_type":"markdown","metadata":{"id":"gzMbypW299ma"},"source":["TensorFlow 자습서에서 신경망을 사용한 회귀 분석 소개\n","회귀 문제에 대한 정의는 여러 가지가 있지만, 여기서는 숫자 예측으로 단순화"]},{"cell_type":"markdown","metadata":{"id":"QbpU6dehGO3-"},"source":["예를 들어 다음과 같이 할 수 있습니다.\n","\n","* 해당 주택에 대한 정보(예: 방 수, 크기, 욕실 수)가 주어진 주택의 판매 가격을 예측합니다.\n","* 이미지에 있는 항목의 경계 상자의 좌표를 예측합니다.\n","* 인구 통계(나이, 성별, 성별, 인종)를 기준으로 개인의 의료 보험 비용을 예측합니다."]},{"cell_type":"markdown","metadata":{"id":"vvb3m0jJGWXN"},"source":["# **신경세포(Biological Neuron) 작동 원리**"]},{"cell_type":"markdown","metadata":{"id":"KENta568GehS"},"source":["<img src=\"https://pds.joins.com/news/component/joongang_sunday/201811/17/a0b23428-c888-43ae-a923-83d2c0055949.jpg\">"]},{"cell_type":"markdown","metadata":{"id":"a8qrtO_5Gfu3"},"source":["- 수상돌기(Dendrite) 는 다른 신경세포의 시냅스(Synapse)로부터 신호를 받아들이는 역할을 한다. \n","- 축색(Axon)은 다른 신경세포에 신호를 전달해 주기 위한 통신선로다. \n","- 축색의 끝에 붙어 있는 시냅스는 다른 뇌세포에 신호를 주는 부분이다. \n","- 수상돌기를 통하여 들어온 신호는 세포체(Nucleus)로 전달된다. \n","- 많은 수상돌기에서 들어온 신호는 세포체에서 하나로 종합된다. \n","- 이것이 축색을 거치고 시냅스를 통하여 다른 세포에 전해진다. \n","- 신경세포에 흐르는 신호는 전기적인 신호다.\n","- 시냅스와 수상돌기 사이에는 작은 틈이 있다. 틈이 있기 때문에 전기 신호가 직접 전달되지 않는다. \n","- 신경세포는 자극이 들어오면 흥분된다.\n","- 신경세포가 흥분되면 외부에 있는 플러스 나트륨 이온(Na+)이 내부로 들어오면서, 세포 안팎의 전압 차이가 바뀐다. 이러한 전압 변화를 ‘활동전위’라 부른다.  \n","- 활동전위가 축색을 따라서 이동하다 보면 축색의 끝에 도달하여 시냅스를 만나게 된다. \n","- 시냅스에는 ‘소포(synaptic vesicle)’라는 것이 있는데, 이것은 신경물질을 간직하고 있다. 시냅스에 활동전위가 도착하면 소포가 터지면서 아세틸콜린이라는 화학 전달물질이 방출된다. \n","- 이 물질은 시냅스를 빠져나가, 다른 세포의 수상돌기 벽을 자극한다. "]},{"cell_type":"markdown","metadata":{"id":"Nwwx1ZVmGnRC"},"source":["# **Perceptron (Artificial Neuron)**: A Basic Unit in Neural Network(NN): \n","\n","__Perceptron with Linear Activation Function__\n","\n","> <img src= \"https://i.stack.imgur.com/75VU8.png\">\n","\n","__Perceptron with Non-Linear Activation Function__\n","\n","> <img src= \"https://www.researchgate.net/profile/Pradeep-Singh-32/publication/283339701/figure/fig2/AS:421642309509122@1477538768781/Single-Layer-Perceptron-Network-Multilayer-Perceptron-Network-These-type-of-feed-forward.png\">\n","\n","### A Typical NN Architecture\n","\n","  - Shallow Neural Network\n","\n","> <img src= \"https://cdn-images-1.medium.com/max/1000/1*3FMmI_9rrB2V7-UuTjQ3dA.png\">\n","\n","  - Deep Neural Network (DNN)\n","\n","> <img src=\"https://www.researchgate.net/publication/324700732/figure/fig1/AS:618579816902662@1524492329855/A-typical-DNN-structure-for-image-object-recognition.png\">\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1HrMOHgLGtFG"},"source":["# **What we're going to cover**\n","- 회귀 모형의 아키텍처\n","- 입력 모양 및 출력 모양\n","    * 'X': 특징/데이터(입력)\n","    * 'y': 레이블(레이블)\n","- 보고 맞출 사용자 지정 데이터 만들기ㅉ\n","- 모델링 단계\n","    * 모델 만들기\n","    * 모델 컴파일\n","        * 손실 함수 정의\n","        * 최적화 도구 설정\n","        * 평가 지표 작성\n","    * 모델 적합(데이터의 패턴을 찾기 위해 모델 가져오기)\n","- 모델 평가\n","    - 모델 시각화(\"시각화, 시각화, 시각화\")\n","    * 교육 곡선 보기\n","    * 예측과 실제 상황 비교(평가 지표 사용)\n","- 모델 저장(나중에 사용할 수 있도록)\n","- 모델 로드\n","\n","<img src=\"https://miro.medium.com/max/2048/1*QV1rVgh3bfaMbtxueS-cgA.png\">"]},{"cell_type":"markdown","metadata":{"id":"iINE1ZUqH-uI"},"source":["Typical architecture of a regresison neural network\n","# **회귀신경망의 전형적인 구조**\n","\n","신경망을 작성하는 방법은 매우 다양함"]},{"cell_type":"markdown","metadata":{"id":"UneqGbZHKF11"},"source":["그러나 다음은 일련의 숫자를 수집하여 패턴을 찾은 다음 대상 번호를 출력하기 위한 일반적인 설정입니다."]},{"cell_type":"markdown","metadata":{"id":"6KU0ZfhDKO2K"},"source":["Typical architecture of a regresison neural network\n","\n","신경망을 작성하는 방법은 매우 다양\n","\n","다음은 일련의 숫자를 수집하여 패턴을 찾은 다음 대상 번호를 출력하기 위한 일반적인 설정입니다.\n","\n","네, 앞의 문장이 모호하지만, 잠시 후 이 문장이 실행되도록 하겠습니다.<br><br>\n","\n","\n","| **Hyperparameter** | **Typical value** |\n","| --- | --- |\n","| Input layer shape | 기능의 수와 동일한 모양(예: #침실, #화장실, #주택 가격 예측의 #차 공간) |\n","| Hidden layer(s) | 특정 문제, 최소 = 1, 최대 = 무제한 |\n","| Neurons per hidden layer | 특정 문제(일반적으로 10~100) |\n","| Output layer shape | 원하는 예측 모양과 동일한 모양(예: 집값의 경우 1) |\n","| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n","| Output activation | None, ReLU, logistic/tanh |\n","| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n","| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n","\n","<br>\n","회귀 네트워크의 일반적인 아키텍처 원본: Aurélien Géron의 Skit-Learn, Keras & TensorFlow Book 293페이지의 Skikit-Learn을 각색한 Hands-On Machine Learning\n","\n","> 🔑 **Note :** 기계 학습에서 하이퍼 파라미터는 데이터 분석가 또는 개발자가 직접 설정할 수 있는 것이며, 매개변수는 일반적으로 모델이 스스로 학습하는 것을 설명합니다(분석가가 명시적으로 설정하지 않은 값)."]},{"cell_type":"code","metadata":{"id":"-DQNly5wdEoq"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLrULd8idgHh"},"source":["# **Creating data to view and fit**\n","\n","** 회귀 분석 문제**(숫자 예측)에 대해 연구하고 있으므로 모형화할 선형 데이터(직선)를 몇 개 생성하겠습니다."]},{"cell_type":"code","metadata":{"id":"MMglNiocdymX"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Create features\n","x = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n","\n","# Create labels\n","y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n","\n","### y = x + 10\n","\n","# 시각화\n","plt.scatter(x, y);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-3N1nWLeKL3"},"source":["Y = tf.expand_dims(tf.constant(y), axis=-1)\n","Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVPz8O6xeUAZ"},"source":["# Data massaging\n","# 데이터를 세로로 붙이는 np.c_\n","X = np.c_[np.ones((8, 1)), x]\n","\n","# 세로로 데이터를 붙여서 2차원 함수로 만듬\n","tensor_X = tf.constant(X, dtype=tf.float32)\n","Y = np.c_[y]\n","tensor_Y = tf.constant(Y, dtype=tf.float32)\n","\n","print(tensor_X)\n","print(tensor_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elIFtLmSfUMD"},"source":["# Using tensorflow and @\n","def betahat(X, Y):\n","    XT  = tf.transpose(X)\n","    XTX = XT @ X\n","    XTX_INV = tf.linalg.inv(XTX)\n","    return XTX_INV @ XT @ Y\n","\n","betahat(tensor_X, tensor_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7N696RMgKaS"},"source":["# Using tensorflow and tf.matmul\n","\n","def betahat(X,Y):\n","  W = tf.matmul(tf.matmul(tf.linalg.inv(tf.matmul(X, X,transpose_a=True)),tf.transpose(X)),Y)\n","  return W.numpy()\n","MYY\n","betahat(tensor_X, tensor_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kb-z3py4hGHd"},"source":["# **Steps in modelling**\n"]},{"cell_type":"markdown","metadata":{"id":"LfAO94lcijNx"},"source":["이제 입력과 출력 형태뿐만 아니라 어떤 데이터가 있는지 알게 되었습니다. 이 데이터를 모델링하기 위한 신경망을 어떻게 구축할 것인지 알아보겠습니다.\n","\n","TensorFlow에서는 일반적으로 모델을 만들고 교육하기 위한 3가지 기본 단계가 있습니다."]},{"cell_type":"markdown","metadata":{"id":"E_TUg0Nvi5_F"},"source":["* 모델 만들기 - 신경 네트워크의 계층을 직접 구성(기능 또는 순차 API 사용)하거나 이전에 구축된 모델(전송 학습이라고 함)을 가져옵니다.\n","* 모델 컴파일 - 모델 성능을 측정하는 방법(손실/측정지표)을 정의하고 개선 방법(최적화 도구)을 정의합니다.\n","* 모형 적합 - 모형에서 데이터에서 패턴을 찾을 수 있습니다(X가 y에 도달하는 방법)."]},{"cell_type":"markdown","metadata":{"id":"9KvOJ5xqnuBo"},"source":["여기서 우리의 목표는 예측하기 위해 X를 사용하는 것입니다.\n","\n","그래서 우리의 입력은 X이고 출력은 y입니다."]},{"cell_type":"code","metadata":{"id":"gDiEjNX5n-WO"},"source":["# Create features\n","X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n","\n","# Create labels\n","Y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n","\n","# Note that y = X+10."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"floURMBpoCQA"},"source":["# Set Random seed\n","tf.random.set_seed(42)\n","\n","# Create a model using the Sequential API\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1)\n","])\n","\n","# Complie the model\n","model.compile(loss=tf.keras.losses.mae, \n","              optimizer=tf.keras.optimizers.SGD(),\n","              metrics=['mae'])\n","\n","# Fit the model\n","model.fit(X, Y, epochs=100)\n","\n","# Get the weight and bias\n","all_weight = model.layers[0].weights\n","all_weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4N1BOM-CpSd6"},"source":["쿵!\n","\n","우리는 방금 X와 Y 사이의 패턴을 알아내기 위한 모델을 훈련시켰습니다.\n","\n","어떻게 된 것 같아?"]},{"cell_type":"code","metadata":{"id":"YELwKwY6o6vd"},"source":["# Cheack out X and Y\n","X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZ1DC5yOpM4t"},"source":["X 값 17.0을 넘겼을 때 어떤 결과가 나와야 한다고 생각하십니까?"]},{"cell_type":"code","metadata":{"id":"awLzAFnCpYlm"},"source":["# Make a prediction with the model\n","model.predict([17.0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ndo2tOzZpczO"},"source":["잘 안 돼... 27.0에 가까운 것을 출력했어야 했어요"]},{"cell_type":"markdown","metadata":{"id":"kkvkbW88piBG"},"source":["# **Improving a model**"]},{"cell_type":"markdown","metadata":{"id":"pJvRgmSEpolP"},"source":["모델을 개선하기 위해 이전에 거쳤던 3단계의 거의 모든 부분을 변경했습니다."]},{"cell_type":"markdown","metadata":{"id":"pfKBnK-ppvaG"},"source":["1. 모델 만들기 - 사용하려는 경우\n","* 층을 더하다\n","* 각 계층 내에서 숨겨진 단위(뉴런이라고도 함)의 수를 늘립니다__\n","* 각 레이어의 활성화 함수를 변경합니다.\n","\n","> [📒 Activation Functions](https://en.wikipedia.org/wiki/Activation_function)\n","\n","> [📒 Activation Functions in Tensorflow-Keras](https://www.tensorflow.org/api_docs/python/tf/keras/activations)"]},{"cell_type":"markdown","metadata":{"id":"eWVfxksAp3Og"},"source":["2. 모델 컴파일 - 원하는 경우\n","* 다른 최적화 함수 사용\n","* 최적화 함수의 학습 속도를 변경합니다.\n","\n","> [📒 An Empirical Comparison of Optimizers for Machine Learning Models](https://heartbeat.fritz.ai/an-empirical-comparison-of-optimizers-for-machine-learning-models-b86f29957050)"]},{"cell_type":"markdown","metadata":{"id":"bMDrVeZcqDgp"},"source":["3. 모형 적합 - 가능한 경우\n","* 모형을 더 많은 에포크로 적합(더 오랜 시간 동안 훈련)\n","* 모델에 배울 수 있는 더 많은 예를 제시합니다."]},{"cell_type":"markdown","metadata":{"id":"JOqw8tPIqVYJ"},"source":["와, 우리가 방금 여러 가지 가능한 단계들을 소개했어 <br>기억해야 할 중요한 것은 이것들을 어떻게 바꾸느냐 하는 것은 당신이 연구하고 있는 문제에 달려있다는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"_mDDlqXuqZFS"},"source":["지금은 단순하게 모델을 더 오래 교육하는 것 뿐입니다(다른 모든 것은 그대로 유지됨)."]},{"cell_type":"code","metadata":{"id":"bK-gvI3aqdO0"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Create a model (same as above)\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1)\n","])\n","\n","# Compile model (same as above)\n","model.compile(loss=tf.keras.losses.mae,\n","              optimizer = tf.keras.optimizers.SGD(),\n","              metrics=['mae'])\n","\n","# Fit model (this time we'll train for longer)\n","model.fit(X, Y, epochs = 100) # train for 100 epochs not 10\n","\n","# Get the weight and bias in layer(0)\n","all_weight = model.layers[0].weights\n","all_weight"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gQf-7O-xrLTH"},"source":["손실 값이 이전보다 감소했음을 알 수 있습니다(에포크 수가 늘어날수록 계속 감소).\n","\n","우리의 모델로 예측했을 때 이것이 무엇을 의미한다고 생각합니까?\n","\n"]},{"cell_type":"code","metadata":{"id":"sfPHNL99rReC"},"source":["# Remind ourselves of what X and y are\n","X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OhAXhvFIrTF4"},"source":["# Try and predict what y would be if X was 17.0\n","model.predict([17.0]) # the right answer is 27.0 (y = X + 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5Ld6NMErVzW"},"source":["훨씬 나아!\n","\n","이번엔 좀 친해졌네요. 그래도 우린 더 나을 수 있어\n","\n","이제 모델을 교육했는데 어떻게 평가해야 할까요?"]},{"cell_type":"markdown","metadata":{"id":"SZ8epdacraa3"},"source":["신경망을 구축할 때 거쳐야 할 일반적인 작업 흐름은 다음과 같습니다"]},{"cell_type":"markdown","metadata":{"id":"AkCBTHq4rfes"},"source":["Build a model -> evaluate it -> build (tweak) a model -> evaulate it -> build (tweak) a model -> evaluate it...<br>\n","모델 제작 -> 평가 -> 모델 제작 (약함) -> 평가 -> 모델 제작 (약함) 평가 -> 평가"]},{"cell_type":"markdown","metadata":{"id":"AQbtPFnWrjai"},"source":["🤣 명심하라: \"실험, 실험, 실험!!!\"\n","\n","이러한 조정은 모델을 처음부터 만드는 것이 아니라 기존 모델을 조정하는 데서 발생할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"59Kcdbd9rl8j"},"source":["# **Evaluating a model**"]},{"cell_type":"markdown","metadata":{"id":"ER577dLNrwKW"},"source":["평가 시 **\"시각화, 시각화, 시각화\"**라는 단어를 기억해야 합니다.\"\n","\n","왜냐하면 당신이 무언가를 생각하는 것보다 무언가를 보는 것이 더 나을 것이기 때문입니다.\n","\n","시각화하는 것이 좋습니다."]},{"cell_type":"markdown","metadata":{"id":"7A2X8c7Br3om"},"source":["* 데이터 - 어떤 데이터로 작업하고 있습니까? 무엇처럼 보이나요?\n","* 모델 자체 - 아키텍처는 어떻게 생겼습니까? 다른 모양들은 무엇인가요?\n","* 모델의 교육 - 모델이 학습하는 동안 어떻게 수행합니까?\n","* 모형의 예측 - 모형의 예측이 지면 진리(원래 라벨)에 대해 어떻게 선형화됩니까?"]},{"cell_type":"markdown","metadata":{"id":"zv1AuiybsCLn"},"source":["먼저 모델을 시각화해 보겠습니다.\n","\n","하지만 먼저 좀 더 큰 데이터셋을 만들고 사용할 수 있는 새로운 모델을 만들 것입니다(이전과 동일하지만 연습을 많이 할수록 좋습니다)."]},{"cell_type":"code","metadata":{"id":"aWdtFG46vOwm"},"source":["# Make a bigger dataset\n","X = np.arange(-100, 100, 4)\n","X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8zQ6t7xvUyf"},"source":["# Make labels for the dataset (adhering to the same pattern as before)\n","Y = np.arange(-90, 110, 4)\n","Y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tyUKav--vZYk"},"source":["Since $y=X+10$, we could make the labels like so:"]},{"cell_type":"code","metadata":{"id":"4dsFDKZ7vcIM"},"source":["# Same result as above\n","Y = X + 10\n","Y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCvz-bipveJE"},"source":["# **Split data into training/test set**"]},{"cell_type":"markdown","metadata":{"id":"1iVoJyESvnR2"},"source":["기계 학습 프로젝트에서 가장 일반적이고 중요한 단계 중 하나는<br>교육 및 테스트 세트(필요한 경우 검증 세트)를 만드는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"VwnhPSbevn9p"},"source":["각 세트는 다음과 같은 용도로 사용 :"]},{"cell_type":"markdown","metadata":{"id":"FfSKJeUSvt8X"},"source":["* Training set - 이 데이터를 통해 학습합니다. 이 데이터는<br> 일반적으로 학기 중 학습하는 과정 자료와 같이 사용 가능한 전체 데이터의 70-80%에 해당합니다.\n","\n","* Validation set - 이 데이터는 일반적으로 최종 시험 전에 치르는<br> 연습 시험과 같이 사용 가능한 총 데이터의 10-15%에 해당하는 모형으로 조정됩니다.\n","\n","* Test set - 이 데이터에 대해 평가하여 학습한 내용을 검정합니다.<br> 일반적으로 사용 가능한 총 데이터의 10-15%(학기 말에 보는 기말고사 등)입니다."]},{"cell_type":"markdown","metadata":{"id":"THM5v23Tv4bo"},"source":["지금은 교육 및 테스트 세트만 사용할 것입니다. 즉, 모델이 학습할 데이터셋과 평가를 받을 데이터셋을 보유하게 됩니다.\n","\n","X 어레이와 Y 어레이를 분할하여 생성할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"hd3ckqfZwGwJ"},"source":["🔑 참고: 이 단계는 일반적으로 프로젝트를 시작할 때 바로 수행됩니다<br>  (테스트 세트는 항상 다른 모든 데이터와 별도로 유지되어야 함).<br> 우리는 모델이 교육 데이터에 대해 학습한 후 테스트 데이터에 대해<br> 평가하여 보이지 않는 예제에 얼마나 잘 일반화되는지 알 수 있기를 원합니다."]},{"cell_type":"code","metadata":{"id":"SlEKfoVKwNd5"},"source":["# Check how many samples we have\n","len(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkj7vlF8wTMR"},"source":["# Split data into train and test sets\n","X_train = X[:40] # first 40 examples (80% of data)\n","Y_train = Y[:40]\n","\n","X_test = X[40:] # last 10 examples (20% of data)\n","Y_test = Y[40:]\n","\n","len(X_train), len(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cY9q0N4IwWB7"},"source":["# **Visualizing the data**"]},{"cell_type":"markdown","metadata":{"id":"VFVxjcK2wkiW"},"source":["이제 교육 및 테스트 데이터가 확보되었으니 시각화하는 것이 좋습니다.\n","\n","뭐가 뭔지 구별할 수 있도록 멋진 색깔로 플롯을 짜보자."]},{"cell_type":"code","metadata":{"id":"aj9FmYTMwtK9"},"source":["plt.figure(figsize=(10, 7))\n","# Plot training data in blue\n","plt.scatter(X_train, Y_train, c='b', label='Training data')\n","# Plot test data in green\n","plt.scatter(X_test, Y_test, c='g', label='Testing data')\n","# Show the legend\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yfmHxxPJxFZk"},"source":["예쁘다! 언제라도 데이터, 모델, 무엇이든 시각화할 수 있다면 좋은 생각입니다.\n","\n","이 그래프를 염두에 두고 파란색 점(X_train)에서 패턴을 학습하여 녹색 점(X_test)을 그리는 모델을 제작하려고 합니다.\n","\n","모델을 만들 시간입니다. 우리는 예전과 똑같은 것을 만들 것이다."]},{"cell_type":"code","metadata":{"id":"EeLQni9JxZSC"},"source":["# Set trandom seed\n","tf.random.set_seed(42)\n","\n","# Create a model (same as above)\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1)\n","])\n","\n","# Compile model (same as above)\n","model.compile(loss=tf.keras.losses.mae,\n","              optimizer=tf.keras.optimizers.SGD(),\n","              metrics=['mae'])\n","\n","# Fit model (same as above)\n","model.fit(X_train, Y_train, epochs=100) # commmented out on purpose (not fitting it just yet)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"necce8IY3ENj"},"source":["# **Visualizing the model**"]},{"cell_type":"markdown","metadata":{"id":"g8PTPOUc3LHD"},"source":["모델을 만든 후에는 모델을 살펴보는 것이 좋습니다(특히 이전에 모델을 많이 만들지 않은 경우).\n","\n","요약()을 호출하여 모델의 도면층과 모양을 볼 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"tC7W8AVy3Nv-"},"source":["🔑 참고: 모델을 시각화하면 입력 및 출력 모양이 일치하지 않을 때 특히 유용합니다."]},{"cell_type":"code","metadata":{"id":"QSLwNySg3RLv"},"source":["# Doesn't work (model not fit/built)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jiqwLUh93SMY"},"source":["아, 위의 셀은 우리가 만든 모델에 맞지 않아서.\n","\n","또한 어떤 입력 형태를 기대해야 하는지도 알려주지 않았습니다.\n","\n","위에서 우리가 입력 쉐이프를 어떻게 논의했는지는 숫자 하나에 불과했던 것을 기억하십니까?\n","\n","첫 번째 도면층에 대한 input_shape 매개변수를 사용하여 모델에 데이터 입력 모양을 알릴 수 있습니다(일반적으로 input_shape이 정의되지 않은 경우 Keras는 자동으로 데이터를 파악하려고 시도함)."]},{"cell_type":"code","metadata":{"id":"xOqLd8D23bAe"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Create a model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.InputLayer(input_shape=[1]),\n","    tf.keras.layers.Dense(1) # define the input_shape to our model\n","    # tf.keras.layers.Dense(1, input_shape=[1]) # define the input_shape to our model\n","])\n","\n","# Compile model\n","model.compile(loss=tf.keras.losses.mae,\n","              optimizer = tf.keras.optimizers.SGD(),\n","              metrics=['mae'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8gFR_-s4Jk3"},"source":["# This will work after specifying the input shape\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YjelVSoH4R2r"},"source":["model.summary()는 모델에 포함된 레이어, 출력 모양 및 파라미터 수를 보여줍니다."]},{"cell_type":"markdown","metadata":{"id":"MQGFx3S14bfP"},"source":["* Total params - 모형의 총 원자 수입니다.\n","* 훈련 가능한 매개변수 - 모델이 훈련할 때 업데이트할 수 있는 매개변수(패턴)입니다.\n","* 교육할 수 없는 매개 변수 - 이러한 매개 변수는 교육 중에 업데이트되지 않습니다(전 학습 중에 다른 모델에서 이미 학습된 패턴을 가져오는 것이 일반적임)."]},{"cell_type":"markdown","metadata":{"id":"wNYcHRx_4eTv"},"source":["📖 리소스: 계층 내에서 교육 가능한 매개변수에 대한 보다<br> 심도 있는 개요는 MIT의 딥러닝 비디오 소개를 참조하십시오."]},{"cell_type":"markdown","metadata":{"id":"5_hF20fG44h0"},"source":["우리의 모델을 학습시켜보자."]},{"cell_type":"code","metadata":{"id":"-z9ktOUR5BhT"},"source":["# Fit the model to the training data\n","model.fit(X_train, Y_train, epochs=100, verbose=2) # verbose controls how much hets output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BRjQbVK5NVy"},"source":["# Check the model summary\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_s-YZmoT5Tt_"},"source":["요약과 함께 다음 명령을 사용하여 모형의 2D 그림을 볼 수도 있습니다. plot model()"]},{"cell_type":"code","metadata":{"id":"lwOPwNi_5Zu7"},"source":["from tensorflow.keras.utils import plot_model\n","plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0p_roUy5kWY"},"source":["우리의 경우, 우리가 사용한 모델은 입력과 출력만 있지만<br>더 복잡한 모델을 시각화하는 것이 디버깅에 매우 도움이 될 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"YPfmdUI95q_X"},"source":["# **Visualizing the predictions**"]},{"cell_type":"markdown","metadata":{"id":"D3Cd9mQ55w37"},"source":["이제 훈련된 모델이 있습니다. 몇 가지 예측을 시각화해 보겠습니다.\n","\n","예측을 시각화하려면 항상 지면 진실 레이블에 대해 그림을 그리는 것이 좋습니다.\n","\n","종종 당신은 이것을 'y_test'의 형태로 볼 것이다. 'y_pred'(근거 진실 대 예측).\n","\n","먼저 검정 데이터에 대한 몇 가지 예측(\"X_test\")을 수행하겠습니다. 이 모형은 테스트 데이터를 본 적이 없습니다."]},{"cell_type":"code","metadata":{"id":"o2kZyUTR52iy"},"source":["# Make predictions\n","y_preds = model.predict(X_test)\n","\n","# View the predictions\n","y_preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aMSC0Lv6SBG"},"source":["좋아요, 숫자 목록을 얻었지만, 이걸 어떻게 실제 라벨과 비교할 수 있죠?\n","\n","플롯 기능을 구축해서 알아보자.\n","\n","🔑 참고: 무언가를 많이 시각화할 것 같으면 나중에 사용할 수 있도록 기능을 설정하는 것이 좋습니다."]},{"cell_type":"code","metadata":{"id":"eWmru4gk6VM0"},"source":["def plot_predictions(train_data=X_train,\n","                     train_labels=Y_train,\n","                     test_data=X_test,\n","                     test_labels=Y_test,\n","                     predictions=y_preds):\n","    \"\"\"\n","    Plots training data, test data and compares predictions.\n","    \"\"\"\n","    plt.figure(figsize=(10, 7))\n","    # Plot training data in blue\n","    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n","    # Plot test data in green\n","    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n","    # Plot the predictions in red (predictions were made on the test data)\n","    plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n","    # Show the legend\n","    plt.legend()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"meq1gIE37uq0"},"source":["plot_predictions (train_data = X_train, \n","                  train_labels=Y_train,\n","                  test_data=X_test,\n","                  test_labels=Y_test,\n","                  predictions=y_preds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-M8PaoJ18RiP"},"source":["줄거리에서 우리는 우리의 예측이 완전히 이상하지는 않다는 것을 알 수 있지만 그것들은 확실히 특별한 것도 아니다."]},{"cell_type":"markdown","metadata":{"id":"QHS7_kw_8bL3"},"source":["# **Evaluating predictions**"]},{"cell_type":"markdown","metadata":{"id":"c5wMq9tdAdYI"},"source":["시각화 해제와 함께 평가 metrics는 모델을 평가하기 위한 최선의 대안 옵션입니다.<br>\n","진행 중인 문제에 따라 모델마다 평가 metrics이 다릅니다."]},{"cell_type":"markdown","metadata":{"id":"Bo9csmARAjXW"},"source":["회귀 문제에 사용되는 두 가지 주요 metrics는 다음과 같습니다."]},{"cell_type":"markdown","metadata":{"id":"2oiXY0iYA-ek"},"source":["* 평균 절대 오차(MAE) - 각 예측 간의 평균 차이입니다.\n","* 평균 제곱 오차(MSE) - 예측 사이의 평균 차이 제곱(오차가 클수록 작은 오차보다 해로운 경우 사용)"]},{"cell_type":"markdown","metadata":{"id":"tpxVeNsEBD2Q"},"source":["각 값이 낮을수록 좋습니다."]},{"cell_type":"markdown","metadata":{"id":"cB6lC_UVBKN9"},"source":["모델 손실과 컴파일 단계 중 설정된 metrics를 반환하는 model.evaluate()도 사용할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"LY2yRUKZBTam"},"source":["# Evaluate the model on the test set\n","model.evaluate(X_test, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ViZVQIDfBZ2_"},"source":["우리의 경우, 손실 함수는 MAE를 사용하였고,<br>\n","메트릭은 MAE를 사용하였으므로 model.evaluate()에서 둘 다 반환하였습니다.\n","\n","텐서플로우에는 MSE와 MAE 기능도 내장돼 있다.\n","\n","많은 평가 함수의 경우, 예측과 truth labels를 비교하는 전제는 동일함"]},{"cell_type":"code","metadata":{"id":"l--xxZ_eB9nY"},"source":["# Calculate the mean absolute error\n","# 평균 절대오차 계산\n","mae = tf.metrics.mean_absolute_error(y_true = Y_test,\n","                                     y_pred = y_preds)\n","mae"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Rea6XhPCuZ_"},"source":["이상하네, MAE는 단일 결과물이어야 해\n","\n","대신, 우리는 10개의 값을 얻습니다.\n","\n","그 이유는 y_test와 y_predensor의 모양이 다르기 때문입니다."]},{"cell_type":"code","metadata":{"id":"tA9ScIU0C5FQ"},"source":["# Check the test label tensor values\n","Y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awCGzGRWC7zt"},"source":["# Check the predictions tensor values (notice the extra square brackets)\n","y_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjMaGbN7DAsL"},"source":["# Check the tensor shapes\n","Y_test.shape, y_preds.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACNCG5O5DDwe"},"source":["여러 가지 입력 및 출력 모양을 처리하는 방법에 대해 논의한 것이 가장 일반적인 문제 중 하나이며, 이때가 바로 이러한 문제 중 하나입니다."]},{"cell_type":"markdown","metadata":{"id":"FbG996Z-DJLd"},"source":["squeeze()를 사용하여 고정할 수 있습니다. 그러면 y_pres 텐서에서 1차원이 제거되어 y_test와 동일한 모양이 됩니다."]},{"cell_type":"markdown","metadata":{"id":"HjIB8-zIDPk3"},"source":["🔑 참고: 두 텐서를 비교하는 경우 올바른 모양인지 확인하는 것이 중요합니다<br>(항상 모양을 조작할 필요는 없지만 항상 주의할 필요가 있습니다.<br> 특히 입력 및 출력 모양이 일치하지 않는 경우 많은 오류가 일치하지 않는 텐서로 인해 발생합니다)."]},{"cell_type":"code","metadata":{"id":"1XocghK0DWQP"},"source":["# Shape before squeeze()\n","y_preds.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfcFxfI3DbjS"},"source":["# Shape after squeeze()\n","y_preds.squeeze().shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbYzZaEcDgFA"},"source":["# What do they look like?\n","Y_test, y_preds.squeeze()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n91KuzxxDnU2"},"source":["이제 y_test 센서와 y_pred 센서를 같은 모양으로 만드는 방법을 배웠습니다. 평가 메트릭스를 사용해 보겠습니다."]},{"cell_type":"code","metadata":{"id":"t7H5I_mcGbGq"},"source":["y_pred=y_preds.squeeze() # use squeeze() to make same shape\n","maey_pred=y_preds.squeeze() # use squeeze() to make same shape\n","maey_pred=y_preds.squeeze() # use squeeze() to make same shape\n","maey_pred=y_preds.squeeze() # use squeeze() to make same shape\n","maey_pred=y_preds.squeeze() # use squeeze() to make same shape\n","mae\n","mae"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-FTd_FoGbjx"},"source":["# Calculate the MSE\n","mse = tf.metrics.mean_squared_error(y_true = Y_test,\n","                                    y_pred = y_preds.squeeze())\n","mse"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vC9Xt0R-HiFR"},"source":["또한 순수 텐서플로우 함수를 사용하여 MAE를 계산할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"UGiorZCfIPnG"},"source":["# Returns the same as tf.metrics.mean_absolute_error()\n","tf.reduce_mean(tf.abs(Y_test-y_preds.squeeze()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2A55iVriIRF2"},"source":["시 한 번, 사용할 수 있다고 생각되는 모든 기능을 반복적으로 사용하는 것이 좋습니다.\n","\n","우리의 평가 지표에 대한 기능을 만들어 봅시다."]},{"cell_type":"code","metadata":{"id":"tD6wDtfqJStq"},"source":["def mae(y_test, y_pred):\n","  \"\"\"\n","  Calculuates mean absolute error between y_test and y_preds.\n","  \"\"\"\n","  return tf.metrics.mean_absolute_error(y_test,\n","                                        y_pred.squeeze()).numpy()\n","  \n","def mse(y_test, y_pred):\n","  \"\"\"\n","  Calculates mean squared error between y_test and y_preds.\n","  \"\"\"\n","  return tf.metrics.mean_squared_error(y_test,\n","                                       y_pred.squeeze()).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nsgDyUTmJXg2"},"source":["# **Running experiments to improve a model**\n"]},{"cell_type":"markdown","metadata":{"id":"nKRiVBjVKmJo"},"source":["평가 메트릭과 모델이 수행하는 예측을 보고 나면 평가 메트릭을 개선하고자 할 가능성이 높습니다.\n","\n","이 작업을 수행하는 방법은 여러 가지가 있지만, 주요 방법 중 3가지는 다음과 같습니다."]},{"cell_type":"markdown","metadata":{"id":"Jp5e40UHKqUT"},"source":["1. 더 많은 데이터 얻기 - 모델에 대해 교육할 수 있는 더 많은 예(패턴을 배울 수 있는 더 많은 기회)를 얻습니다.\n","모델을 더 크게 만듭니다(더 복잡한 모델 사용). \n","2. 각 레이어에서 더 많은 레이어 또는 더 많은 숨겨진 단위의 형태로 나타날 수 있습니다.\n","3. 더 오래 교육 - 모형이 데이터에서 패턴을 찾을 수 있는 기회를 더 많이 제공합니다."]},{"cell_type":"markdown","metadata":{"id":"pLpO40ojK1i9"},"source":["데이터셋을 만들었기 때문에 더 많은 데이터를 쉽게 만들 수 있었지만<br> 실제 데이터셋으로 작업할 때는 항상 그렇지 않습니다."]},{"cell_type":"markdown","metadata":{"id":"6hcBGVIqK6P3"},"source":["그럼 2와 3을 사용하여 모델을 개선할 수 있는 방법을 살펴보겠습니다.\n","\n","이를 위해 3가지 모델을 제작하고 그 결과를 비교할 것입니다."]},{"cell_type":"markdown","metadata":{"id":"NnVxZnQoLCPn"},"source":["1. model_1 - 100Epoch에 대해 훈련된 원래 모델과 동일, 도면층 1개.\n","2. model_2 - 2 레이어, 100Epoch에 대해 교육됩니다.\n","3. model_3 - 2 레이어, 500Epoch에 대해 교육됨."]},{"cell_type":"markdown","metadata":{"id":"5mAyLzH2MkGj"},"source":["## Build mode_1"]},{"cell_type":"code","metadata":{"id":"aksZjaDMLIAt"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Replicate original model\n","model_1 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(1)\n","])\n","\n","# Compile the model\n","model_1.compile(loss=tf.keras.losses.mae,\n","                optimizer=tf.keras.optimizers.SGD(),\n","                metrics=['mae'])\n","\n","# Fit the model\n","model_1.fit(X_train, Y_train, epochs=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pijNInSzLM0U"},"source":["# Make and plot predictions for model_1\n","y_preds_1 = model_1.predict(X_test)\n","plot_predictions(predictions=y_preds_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CtDfSIMONNhu"},"source":["# Calculate model_1 metrics\n","mae_1 = mae(Y_test, y_preds_1)\n","mse_1 = mse(Y_test, y_preds_1)\n","mae_1, mse_1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swCo9hUFLYHl"},"source":["## BIild model_2\n","이번에는 다른 모든 것은 동일하게 유지하면서<br>\n","추가 밀도 레이어(현재 모델에는 2 레이어가 있음)를 추가할 예정입니다."]},{"cell_type":"code","metadata":{"id":"F88cHb16MAog"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Replicate model_1 and add an extra layer\n","model_2 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(1),\n","  tf.keras.layers.Dense(1) # add a second layer\n","])\n","\n","# Compile the model\n","model_2.compile(loss=tf.keras.losses.mae,\n","                optimizer=tf.keras.optimizers.SGD(),\n","                metrics=['mae'])\n","\n","# Fit the model\n","model_2.fit(X_train, Y_train, epochs=100, verbose=1) # set verbose to 0 for less output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q63wf7bhLiBD"},"source":["# Make and plot predictions for model_2\n","y_preds_2 = model_2.predict(X_test)\n","plot_predictions(predictions=y_preds_2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCfgQVUdNh_R"},"source":["와, 벌써 좋아졌네! 그리고 한 겹 더 쌓기만 하면 돼"]},{"cell_type":"code","metadata":{"id":"SzDjaYe-OBC9"},"source":["# Calculate model_2 metrics\n","mae_2 = mae(Y_test, y_preds_2)\n","mse_2 = mse(Y_test, y_preds_2)\n","mae_2, mse_2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZ0CikNCOa_y"},"source":["## Build model_3"]},{"cell_type":"markdown","metadata":{"id":"XQDcUyIEShvH"},"source":["세 번째 모델의 경우 모든 것을 model_2와 동일하게 유지하되,<br> 이번에는 100이 아닌 500에포크를 더 오래 훈련할 것입니다.\n","\n","이것은 우리 모델이 데이터의 패턴을 배울 수 있는 더 많은 기회를 줄 것입니다."]},{"cell_type":"code","metadata":{"id":"MDo0sT3rSuFh"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Replicate model_2\n","model_3 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(1),\n","  tf.keras.layers.Dense(1)\n","])\n","\n","# Compile the model\n","model_3.compile(loss=tf.keras.losses.mae,\n","                optimizer=tf.keras.optimizers.SGD(),\n","                metrics=['mae'])\n","\n","# Fit the model (this time for 500 epochs, not 100)\n","model_3.fit(X_train, Y_train, epochs=500, verbose=0) # set verbose to 0 for less output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrXlpelTSzW9"},"source":["# Make and plot predictions for model_3\n","y_preds_3 = model_3.predict(X_test)\n","plot_predictions(predictions=y_preds_3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eb6dsW-ES6Cp"},"source":["이상하네, 우리가 더 오래 훈련했는데 우리 모델이 성적이 더 나빴나?\n","\n","알고 보니 우리 모델이 너무 오래 훈련해서 결과가 더 나빴을 수도 있습니다(나중에 너무 오랫동안 훈련을 하지 못하게 하는 방법을 알게 될 것입니다)."]},{"cell_type":"code","metadata":{"id":"6Cd5O_a6S-yc"},"source":["# Calculate model_3 metrics\n","mae_3 = mae(Y_test, y_preds_3)\n","mse_3 = mse(Y_test, y_preds_3)\n","mae_3, mse_3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZESvHNeMTBK7"},"source":["# **Comparing results**"]},{"cell_type":"markdown","metadata":{"id":"RmbOjzRCTKlY"},"source":["이제 유사하지만 약간 다른 3가지 결과가 나왔으니 비교해 봅시다."]},{"cell_type":"code","metadata":{"id":"9fMZf1obTMzD"},"source":["model_results = [[\"model_1\", mae_1, mse_1],\n","                 [\"model_2\", mae_2, mse_2],\n","                 [\"model_3\", mae_3, mse_3]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9EpqYO1GTON0"},"source":["import pandas as pd\n","all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n","all_results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A9d0goqETPkt"},"source":["저희 실험 결과, 모델_2가 가장 좋은 성적을 낸 것 같습니다.\n","\n","이제 여러분은 \"모델 비교는 지루하다\"고 생각할 수 있습니다.\"<br>확실히 그럴 수 있습니다. 여기서는 3가지 모델만 비교했습니다.\n","\n","하지만 이것은 기계 학습 모델링의 일부로서, 다양한 모델의 조합을 시도하고<br> 어떤 것이 가장 잘 수행되는지 확인하는 것입니다.\n","\n","여러분이 만든 각 모델은 작은 실험입니다.\n","\n","또한 여러분이 생각하는 (모델을 더 오래 교육시키는 것과 같은) 것이 항상 효과가 있지는 않을 수도 있고<br> 그 반대인 경우도 종종 있다는 것을 알게 될 것입니다."]},{"cell_type":"markdown","metadata":{"id":"u3Fx3o9NTbs2"},"source":["# **Tracking your experiments**"]},{"cell_type":"markdown","metadata":{"id":"lgKBWVJnTmm1"},"source":["정말 좋은 습관 중 하나는 어떤 것이 다른 것보다 더 잘 수행되는지<br> 알아보기 위해 당신의 모델링 실험을 추적하는 것입니다.\n","\n","위의 간단한 버전(결과를 다른 변수에 보관)을 수행했습니다."]},{"cell_type":"markdown","metadata":{"id":"g01Bfb5WTtVE"},"source":["📖 리소스: 하지만 모델을 더 많이 구축할수록 다음과 같은 도구를 사용하는 방법을 모색해야 합니다."]},{"cell_type":"markdown","metadata":{"id":"dyKEb2qUTyYc"},"source":["* TensorBoard - 모델링 실험을 추적하는 데 도움이 되는 TensorFlow 라이브러리의 구성요소입니다<br>(이 내용은 나중에 확인하겠습니다).\n","* Weights & Bias - 모든 종류의 기계 학습 실험을 추적하기 위한 도구입니다<br>(Weights & Bias의 좋은 소식은 TensorBoard에 연결된다는 것입니다)."]},{"cell_type":"markdown","metadata":{"id":"gq7qcy1zT3Hu"},"source":["# **Saving a model**"]},{"cell_type":"markdown","metadata":{"id":"pXs4CVVwT-G4"},"source":["모델을 교육하고 원하는 대로 작동하는 모델을 찾은 후에는 다른 곳<br>(예: 웹 애플리케이션 또는 모바일 장치)에서 사용할 수 있도록 저장할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"9ZRCtcX-UBcX"},"source":["model.save()를 사용하여 TensorFlow/Keras 모델을 저장할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"NQk2cZOPUHRB"},"source":["TensorFlow에는 두 가지 방법으로 모델을 저장할 수 있습니다.\n","\n","* 저장된 모델 형식(기본값).\n","* HDF5 형식입니다.\n"]},{"cell_type":"markdown","metadata":{"id":"JLgrHirvUMXd"},"source":["둘의 주요 차이점은 저장된 모델이 모델을 다시 로드할 때 추가 수정 없이<br> 사용자 지정 객체(예: 특수 도면층)를 자동으로 저장할 수 있다는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"Z3u8rC7oUP9Y"},"source":["어떤 걸로 할까요?\n","\n","상황에 따라 다르지만 대부분의 경우 저장된 모델 형식으로도 충분합니다.\n","\n","두 메서드 모두 동일한 메서드 호출을 사용합니다."]},{"cell_type":"code","metadata":{"id":"Lw-Aw_mPUTIK"},"source":["# Save a model using the SavedModel format\n","model_2.save('best_model_SavedModel_format')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4m9g9jYBUYcf"},"source":["# Check it out - outputs a protobuf binary file (.pb) as well as other files\n","!ls best_model_SavedModel_format"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_QLWYeVUfru"},"source":["이제 모델을 HDF5 형식으로 저장하겠습니다. 동일한 방법으로 파일 이름을 변경하겠습니다."]},{"cell_type":"code","metadata":{"id":"GIrrbRpYUpNW"},"source":["# Save a model using the HDF5 format\n","model_2.save(\"best_model_HDF5_format.h5\") # note the addition of '.h5' on the end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1mvMxYy2Uq1M"},"source":["# Check it out\n","!ls best_model_HDF5_format.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iSVlbWxfUsLs"},"source":["# **ckpt, pb, h5 차이점?**"]},{"cell_type":"markdown","metadata":{"id":"StoUUyhMUvXC"},"source":["  - ckpt 파일\n","> tensorflow 로 학습시킨 딥러닝 모델을 저장하는 방법중 하나로 Checkpoint를 이용하는 방법이 있다.\n","Checkpoint 파일을 저장하고 불러옴으로써 학습된 모델을 재사용하고, 지난 학습을 이어서 더 하고 하는 작업들이 가능해진다.일반적으로 이야기하는 ckpt파일은 .ckpt-data와 같으며, 딥러닝 모델을 제외한 학습한 가중치(weight)만 있는 파일. 모델 구조(graph)는 저장하지 않는다.\n","\n","    - .ckpt-meta : 모델(graph)만 있는 파일\n","    - .ckpt-data : 딥러닝 모델을 제외한 학습한 가중치(weight)만 있는 파일. 모델 구조(graph)는 저장하지 않는다.\n","\n","  - pb 파일\n","> 모델 구조와 가중치(weight) 모두 저장된 파일. freeze_graph.py를 통해서 만들 수 있고,'그래프를 프리징시킨다.'라고 하면 pb파일을 만들 것이라는 뜻이다.\n","\n","  - h5 파일\n","> Hierarchical Data Format (HDF)형식으로 저장되는 데이터. Keras에서는 모델 및 가중치(weight) 모두를 가지고 있는 단일 파일로 저장되면 확장자는 .h5 이다."]},{"cell_type":"markdown","metadata":{"id":"D-y7fG99Wtd7"},"source":["# **Loading a model**"]},{"cell_type":"markdown","metadata":{"id":"7jmxVEIVW_OS"},"source":["load_model() 방법을 사용하여 저장된 모델을 로드할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"Na_-70S6XDDU"},"source":["다른 형식(저장된 모델 및 HDF5)에 대한 모델을 로드하는 것은 동일합니다<br>(특정 형식에 대한 경로 이름이 올바른 경우)."]},{"cell_type":"code","metadata":{"id":"lZwt6KVAXIqj"},"source":["# Load a model from the SavedModel format\n","loaded_saved_model = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n","loaded_saved_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19jYki8vXO5Q"},"source":["이제 시험해 봅시다."]},{"cell_type":"code","metadata":{"id":"vOu9Ke2WXZ7q"},"source":["# Compare model_2 with the SavedModel version (should return True)\n","model_2_preds = model_2.predict(X_test)\n","saved_model_preds = loaded_saved_model.predict(X_test)\n","mae(Y_test, saved_model_preds) == mae(Y_test, model_2_preds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QEdvwtoLXcJV"},"source":["HDF5에서 로드하는 것은 거의 동일합니다."]},{"cell_type":"code","metadata":{"id":"A-ZD1nn6XiyN"},"source":["# Load a model from the HDF5 format\n","loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n","loaded_h5_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZavd1XkXj0u"},"source":["# Compare model_2 with the loaded HDF5 version (should return True)\n","h5_model_preds = loaded_h5_model.predict(X_test)\n","mae(Y_test, h5_model_preds) == mae(Y_test, model_2_preds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"87hKOVFeXnj4"},"source":["# **Downloading a model (from Google Colab)**"]},{"cell_type":"markdown","metadata":{"id":"lbgxfNYfXqvy"},"source":["Google Collab에서 로컬 컴퓨터로 모델을 가져오려고 하면 다음 작업 중 하나를 수행할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"-lG4W7DvXt1-"},"source":["* 파일 창에서 파일을 마우스 오른쪽 버튼으로 클릭하고 '다운로드'를 클릭합니다.\n","* 아래 코드를 사용합니다."]},{"cell_type":"code","metadata":{"id":"4yCL6jTqXxwK"},"source":["# Download the model (or any file) from Google Colab\n","from google.colab import files\n","files.download(\"best_model_HDF5_format.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovhDky0KXznV"},"source":["!ls /content\n","!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NaF4FdMdX6Dc"},"source":["# **A larger example**"]},{"cell_type":"markdown","metadata":{"id":"10CaONcIX8YU"},"source":["지금까지 TensorFlow에서 신경망 회귀 모델을 구축하는 기본 원리를 살펴보았습니다.\n","\n","이제 한 단계 더 높여 기능이 풍부한 데이터를 위한 모델을 구축해 보겠습니다.\n","\n","좀 더 구체적으로, 우리는 연령, 성별, bmi, 어린이, 흡연_상태, 주거_지역과 같은<br> 여러 가지 요인을 바탕으로 개인의 의료보험 비용을 예측하려고 합니다."]},{"cell_type":"markdown","metadata":{"id":"kHadgh24YBvt"},"source":["이를 위해, 우리는 Kaggle과 GitHub에서 호스팅되는 공공 의료 비용 데이터셋을 활용할 것입니다."]},{"cell_type":"code","metadata":{"id":"3b71wTirYJsB"},"source":["# Import required libraries\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQ0wPIxbYLBS"},"source":["# Read in the insurance dataset\n","insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n","insurance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LoPKBrOgYMJ2"},"source":["# Check out the insurance dataset\n","insurance.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8fNSGkQYNwt"},"source":["insurance.tail(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUpyt0iZYPJg"},"source":["insurance[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_JGwMv2YQqU"},"source":["# **Dataframe Indexing**"]},{"cell_type":"markdown","metadata":{"id":"3Luf1ylkYUF5"},"source":["* '열 이름' : df['age] 또는 df.page 사용\n","* 사용 목록: df['name',sex']\n","* pd.loc 사용: df.loc[행, [열 목록]\n","* pd.iloc 사용: df.iloc[row_index, [col_index]"]},{"cell_type":"code","metadata":{"id":"GLUzNOUiYa1G"},"source":["# Method 1\n","\n","insurance['age'].head()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-ZNV7tFYcJU"},"source":["# Another way\n","\n","insurance.sex.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7ec1SUtYdWt"},"source":["# Method 2\n","\n","insurance[['age','sex']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIxN8DbQYfA1"},"source":["# Method 3\n","\n","insurance.loc[10:12,['age','bmi']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8872xEdPYgK7"},"source":["# Method 4\n","\n","insurance.iloc[:,[0,2]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJEvHOM_YhJX"},"source":["insurance.value_counts(['smoker','region'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHssUi_JYiL5"},"source":["insurance.corr()\n","# 탐색적 데이터분석\n","# EDA (Exploratory Data Analysis)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WawCJPx7Yjr1"},"source":["import seaborn as sns\n","\n","sns.pairplot(insurance[[\"charges\", \"age\", \"bmi\", \"children\"]], diag_kind=\"kde\")   # kde (Kernel Density Estimate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SbEwrhxdYlGk"},"source":["비숫자 열을 숫자로 변환해야 합니다(신경망이 비숫자 입력을 처리할 수 없기 때문입니다).\n","\n","그러기 위해 판다에게 get_dummies() 방법을 사용하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"BbtMOXhfYscC"},"source":["성별, 흡연자 및 영역 열과 같은 범주형 변수를 단일 핫 인코딩을 사용하여 숫자 변수로 변환합니다."]},{"cell_type":"code","metadata":{"id":"XPs-uZFxYvFo"},"source":["# Turn all categories into numbers\n","insurance_one_hot = pd.get_dummies(insurance)\n","insurance_one_hot.head() # view the converted columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mpxmHxnpYwMS"},"source":["이제 데이터를 피쳐(X)와 레이블(y)로 분할하겠습니다."]},{"cell_type":"code","metadata":{"id":"W79vheGyY3m9"},"source":["# Create X & y values\n","X = insurance_one_hot.drop(\"charges\", axis=1)\n","Y = insurance_one_hot[\"charges\"]\n","Y.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RwVgkRGDY6ph"},"source":["[__Ambiguity in Pandas Dataframe / Numpy Array “axis” definition__](https://stackoverflow.com/questions/25773245/ambiguity-in-pandas-dataframe-numpy-array-axis-definition)\n","\n","Panda 데이터 프레임의 모호성 / Numpy Array \"축\" 정의"]},{"cell_type":"markdown","metadata":{"id":"TBhZUx3CY_Y0"},"source":["0=down 및 1=down으로 기억하는 것이 가장 간단할 것입니다.\n","\n","이는 다음을 의미합니다."]},{"cell_type":"markdown","metadata":{"id":"BOfiLq4aZHdy"},"source":["* axis=0을 사용하여 각 열을 따라 내려가거나 행 레이블(지수)에 메서드를 적용합니다.\n","* 각 행에 걸쳐 또는 열 레이블에 방법을 적용하려면 axis=1을 사용합니다."]},{"cell_type":"markdown","metadata":{"id":"jO07HIPQZNGL"},"source":["<img src=\"https://i.stack.imgur.com/DL0iQ.jpg\">\n"]},{"cell_type":"code","metadata":{"id":"InHxsuW4ZTlx"},"source":["# View features\n","X.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GVYUq0DvZVi8"},"source":["교육 및 테스트 세트를 만들 수 있습니다. 이 작업을 수동으로 수행할 수도 있지만, 보다 쉽게 하기 위해 Skikit-Learn에서 이미 사용 가능한 train_test_split 기능을 활용할 것입니다."]},{"cell_type":"code","metadata":{"id":"NQlWu0k-ZaJ5"},"source":["# Create training and test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, \n","                                                    Y, \n","                                                    test_size=0.2, \n","                                                    random_state=42) # set random state for reproducible splits\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iJrZ1uLNZfay"},"source":["이제 모델을 제작하고 맞출 수 있습니다(model_2와 동일하게 제작)."]},{"cell_type":"code","metadata":{"id":"EvUgmI_MZlep"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Create a new model (same as model_2)\n","insurance_model = tf.keras.Sequential([\n","  tf.keras.layers.Dense(1),\n","  tf.keras.layers.Dense(1)\n","])\n","\n","# Compile the model\n","insurance_model.compile(loss=tf.keras.losses.mae,\n","                        optimizer=tf.keras.optimizers.SGD(),\n","                        metrics=['mae'])\n","\n","# Fit the model\n","insurance_model.fit(X_train, Y_train, epochs=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oI5mOIXIZo1l"},"source":["# Check the results of the insurance model\n","insurance_model.evaluate(X_test, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eO88q_mIZsq9"},"source":["우리 모델이 성능이 별로 안 좋았으니까 더 큰 모델로 해보자.\n","\n","다음 세 가지를 시도해 보겠습니다.\n","\n","* 레이어 수를 늘립니다(2 -> 3).\n","* 각 레이어의 단위 수를 늘립니다(출력 레이어 제외).\n","* 최적화 도구 변경(SGD에서 Adam으로).<br>\n","다른 모든 것은 그대로 유지될 것이다."]},{"cell_type":"code","metadata":{"id":"PWEdHTl5Z0fw"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Add an extra layer and increase number of units\n","insurance_model_2 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(100), # 100 units\n","  tf.keras.layers.Dense(10), # 10 units\n","  tf.keras.layers.Dense(1) # 1 unit (important for output layer)\n","])\n","\n","# Compile the model\n","insurance_model_2.compile(loss=tf.keras.losses.mae,\n","                          optimizer=tf.keras.optimizers.Adam(), # Adam works but SGD doesn't \n","                          metrics=['mae'])\n","\n","# Fit the model and save the history (we can plot this)\n","history = insurance_model_2.fit(X_train, Y_train, epochs=100, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLFcQs7CZ8Zo"},"source":["insurance_model_2.summary()\n","from tensorflow.keras.utils import plot_model\n","\n","plot_model(insurance_model_2, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1Kx5y26aA9n"},"source":["# Evaluate our larger model\n","insurance_model_2.evaluate(X_test, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9qPNJhkkaFV-"},"source":["훨씬 나아! 더 큰 모형과 Adam 최적화 도구를 사용하면 이전 모형보다 오차가 거의 절반에 달합니다."]},{"cell_type":"markdown","metadata":{"id":"abkxvtyoaJ-3"},"source":["🔑 참고: 많은 문제에서 Adam Optimizer는 훌륭한 시작 옵션입니다.<br>더 자세한 내용은 신경 네트워크 훈련을 위한 A Recipe에서 Andrei Karpathy의 \"Adam is safe\"를 참조하십시오."]},{"cell_type":"markdown","metadata":{"id":"FOgzWkZdaO9C"},"source":["우리 모델의 손실 곡선을 살펴보자, 하향 추세가 보일 거야."]},{"cell_type":"code","metadata":{"id":"KBnaLlZ0aSSr"},"source":["# Plot history (also known as a loss curve)\n","pd.DataFrame(history.history).plot()\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epochs\");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fbB-vrEBaZnL"},"source":["이로 인해 모델의 손실(및 MAE)이 모두 감소하고 있는 것으로 보입니다<br>(우리의 경우 MAE와 손실은 동일하므로 그림의 선이 서로 겹칩니다).\n","\n","더 오래 훈련시키면 손실이 줄어들 수 있다는 것을 말해줍니다."]},{"cell_type":"markdown","metadata":{"id":"OzPXWIzfaeEl"},"source":["🤔 질문: 당신은 얼마나 훈련해야 합니까?\n","\n","당신이 어떤 문제를 해결하느냐에 달렸어요. 어떤 때는 훈련이 그리 오래 걸리지 않을 때도 있고, 어떤 때는 생각보다 오래 걸릴 때도 있습니다. 일반적인 방법은 모델 교육을 매우 오랜 시간(예: 1,000개의 epoch) 동안 설정하지만, 개선이 중지되면 자동으로 중지되도록 EarlyStopping 콜백을 사용하여 설정하는 것입니다. 다른 모듈에서 볼 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"-wQQqSUlak4y"},"source":["위와 같은 모델을 조금 더 훈련해 봅시다. 우린 할 수 있지만 다시 할 수 있어"]},{"cell_type":"code","metadata":{"id":"LN-izSQ_aoo2"},"source":["# Try training for a little longer (100 more epochs)\n","history_2 = insurance_model_2.fit(X_train, Y_train, epochs=100, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mho41hDRapxt"},"source":["추가 훈련은 어떻게 됐어요?"]},{"cell_type":"code","metadata":{"id":"UCFxRMK-aury"},"source":["# Evaluate the model trained for 200 total epochs\n","insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test, Y_test)\n","insurance_model_2_loss, insurance_model_2_mae"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVyLq4ZDawYa"},"source":["100에포크를 추가하기 위한 훈련은 10%의 오차가 줄어듭니다.\n","\n","비주얼 어때요?"]},{"cell_type":"code","metadata":{"id":"oYHCzyz1a1ig"},"source":["# Plot the model trained for 200 total epochs loss curves\n","pd.DataFrame(history_2.history).plot()\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epochs\"); # note: epochs will only show 100 since we overrid the history variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRF3cxqoa3GJ"},"source":["# **Preprocessing data (normalization and standardization)**"]},{"cell_type":"markdown","metadata":{"id":"BfV1jeu2a_Zs"},"source":["데이터 사전 처리(정규화 및 표준화)"]},{"cell_type":"markdown","metadata":{"id":"YZcIOOXZbBMc"},"source":["신경망을 다룰 때 공통적으로 신경망에 전달되는 모든 데이터가 0에서 1의 범위 내에 있는지 확인하는 것이 관례입니다.\n","\n","이 관행을 정규화라고 합니다(예: 0에서 100,000 사이의 모든 값을 0과 1 사이의 값으로 스케일링).\n","\n","모든 데이터를 단위 분산과 0 평균으로 변환하는 또 다른 공정 호출 표준화가 있습니다.\n","\n","이러한 두 가지 방법은 종종 사전 처리 파이프라인(신경망에서 사용할 데이터를 준비하는 일련의 기능)의 일부입니다.\n","\n","이 사실을 알면서 신경망에 대한 데이터를 사전 처리하기 위해 수행해야 할 주요 단계는 다음과 같습니다."]},{"cell_type":"markdown","metadata":{"id":"3QNre3kXbEKw"},"source":["* 모든 데이터를 숫자로 변환합니다(신경 네트워크는 문자열을 처리할 수 없음).\n","* 데이터가 올바른 모양인지 확인합니다(입력 및 출력 모양 확인)."]},{"cell_type":"markdown","metadata":{"id":"arDytlHXbN_A"},"source":["* [**Feature scaling**](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler):\n","    * 데이터 정규화(모든 값이 0과 1 사이인지 확인). 이 값은 최소값을 뺀 다음 최대값에서 최소값을 뺀 값으로 나눕니다. 이를 최소-최대 스케일링이라고도 합니다.\n","    * 표준화(모든 값의 평균이 0이고 분산이 1인지 확인). 이 값은 목표 피쳐에서 평균 값을 뺀 다음 표준 편차로 나누어 구합니다.\n","    * 어떤 걸로 할까요?\n","        * 신경 네트워크가 0과 1 사이의 값을 선호하기 때문에 정규화를 선호하는 경향이 있지만(특히 이미지 처리 시 볼 수 있음), 신경 네트워크는 최소 기능 확장으로 꽤 잘 수행할 수 있음을 종종 발견할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"7ECqAb3SbXfN"},"source":["📖 리소스: 데이터 사전 처리에 대한 자세한 내용은 다음 리소스를 참조하십시오.\n","\n","* [Scikit-Learn's documentation on preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data).\n","* [Scale, Standardize or Normalize with Scikit-Learn by Jeff Hale](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02).\n"]},{"cell_type":"markdown","metadata":{"id":"T0wc-wT8btSh"},"source":["이미 get_dummies()를 사용하여 데이터를 숫자로 변환했습니다. 정규화 방법도 알아보겠습니다."]},{"cell_type":"code","metadata":{"id":"EmkEz_GYb05Y"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","# Read in the insurance dataset\n","insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDGdi1Z8b25y"},"source":["# Check out the data\n","insurance.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Angawknb4eT"},"source":["이전과 마찬가지로 숫자가 아닌 열을 숫자로 변환해야 합니다.<br> 이번에는 범위가 다른 숫자 열도 정규화합니다(모두 0과 1 사이인지 확인)."]},{"cell_type":"markdown","metadata":{"id":"4nl9g3QRb7gS"},"source":["이를 위해 Scikit-Learn의 몇 가지 클래스를 사용할 것입니다."]},{"cell_type":"markdown","metadata":{"id":"R6ZyleTyb_dA"},"source":["* make_column_transformer - 다음 변환에 대한 다단계 데이터 사전 처리 기능을 구축합니다.\n","    * MinMaxScaler - 모든 숫자 열이 정규화되었는지 확인합니다(0과 1 사이).\n","    * OneHotEncoder - 숫자가 아닌 열을 핫 인코딩합니다."]},{"cell_type":"markdown","metadata":{"id":"Sv1awbDrcEz9"},"source":["그들이 움직이는 것을 보자."]},{"cell_type":"code","metadata":{"id":"hgoYy6e9cTOL"},"source":["from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","\n","# Create column transformer (this will help us normalize/preprocess our data)\n","# column transformer 생성(데이터 정규화/사전 처리에 도움이 됨)\n","ct = make_column_transformer(\n","    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n","    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",")\n","\n","# Create X & Y\n","X = insurance.drop(\"charges\", axis=1)\n","Y = insurance[\"charges\"]\n","\n","# Build our train and test sets (use random state to ensure same split as before)\n","# 학습 구조 및 테스트 세트 구축(이전과 동일한 분할을 위해 랜덤 상태 사용)\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n","# 교육 데이터에만 column transformer 적합(테스트 데이터를 계속 사용하면 데이터 누수가 발생할 수 있음)\n","ct.fit(X_train)\n","\n","# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n","# 정규화(MinMaxScalar) 및 단일 핫 인코딩(OneHotEncoder)으로 교육 및 테스트 데이터 변환\n","X_train_normal = ct.transform(X_train)\n","X_test_normal = ct.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMKAKlbTcZKQ"},"source":["이제 표준화하고 단일 핫 인코딩을 수행했습니다. 이제 데이터는 어떻게 표시됩니까?"]},{"cell_type":"code","metadata":{"id":"5ceEte9pc764"},"source":["# Non-normalized and non-one-hot encoded data example\n","X_train.loc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qD6niPpc9E2"},"source":["# Normalized and one-hot encoded example\n","X_train_normal[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bT39SFCUc-4K"},"source":["모양은 어때?"]},{"cell_type":"code","metadata":{"id":"Dt3Hkwv1dCuu"},"source":["# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n","# 추가 컬럼으로 인해 정규화/원핫 인코딩 쉐이프가 더 커집니다.\n","X_train_normal.shape, X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zgMaM-STdGc7"},"source":["우리의 데이터는 정규화되었고 수치화되었으니, 모형화해 봅시다.\n","\n","보험_모델_2과 같은 모델을 사용하겠습니다."]},{"cell_type":"code","metadata":{"id":"wqAv0xTAdJ-R"},"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# Build the model (3 layers, 100, 10, 1 units)\n","insurance_model_3 = tf.keras.Sequential([\n","  tf.keras.layers.Dense(100),\n","  tf.keras.layers.Dense(10),\n","  tf.keras.layers.Dense(1)\n","])\n","\n","# Compile the model\n","insurance_model_3.compile(loss=tf.keras.losses.mae,\n","                          optimizer=tf.keras.optimizers.Adam(),\n","                          metrics=['mae'])\n","\n","# Fit the model for 200 epochs (same as insurance_model_2)\n","insurance_model_3.fit(X_train_normal, Y_train, epochs=200, verbose=1) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R1NiEoL7dLHO"},"source":["정규화된 테스트 세트에 대해 모형을 평가합니다."]},{"cell_type":"code","metadata":{"id":"BkVluPAFdSzK"},"source":["# Evaulate 3rd model\n","insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ugbtLYwVdX3f"},"source":["마지막으로, insurance_model_2(비정규화된 데이터에 대해 교육됨)와 <br>insurance_model_3(정규화된 데이터에 대해 교육됨)의 결과를 비교하겠습니다."]},{"cell_type":"code","metadata":{"id":"d1Zmw9BsderQ"},"source":["# Compare modelling results from non-normalized data and normalized data\n","# 표준화되지 않은 데이터와 정규화된 데이터의 모델링 결과 비교\n","insurance_model_2_mae, insurance_model_3_mae"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-aALBPkwdoXj"},"source":["이를 통해 데이터를 정규화하지 않는 것보다 동일한 모델을 사용하여 10% 적은 오차를 얻을 수 있습니다.\n","\n","이것이 정규화의 주요 이점 중 하나입니다. 즉, 수렴 시간이 더 빨라진다는 것입니다<br>(모형이 더 나은 결과를 더 빨리 얻을 수 있다는 멋진 표현입니다.\n","\n","insurance_model_2는 교육을 더 오래 두면 결국 insurance_model_3과 동일한 결과를 얻을 수 있습니다.\n","\n","하지만 신경 네트워크 실무자로서 우리의 주된 목표는 실험 간격을 줄이는 것이기 때문에,<br> 더 빨리 더 좋은 결과를 얻을 수 있는 것은 무엇이든 좋습니다."]},{"cell_type":"markdown","metadata":{"id":"pstmXfPedtGV"},"source":["# **📖 Extra curriculum**"]},{"cell_type":"markdown","metadata":{"id":"Vz3_ua8Od5OK"},"source":["\n","If you're looking for extra materials relating to this notebook, I'd check out the following:\n","\n","* [MIT introduction deep learning lecture 1](https://www.youtube.com/watch?v=5tvmMX8r_OM) - gives a great overview of what's happening behind all of the code we're running.\n","* Reading: 1-hour of [Chapter 1 of Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielson - a great in-depth and hands-on example of the intuition behind neural networks.\n","\n","To practice your regression modelling with TensorFlow, I'd also encourage you to look through [Lion Bridge's collection of datasets](https://lionbridge.ai/datasets/) or [Kaggle's datasets](https://www.kaggle.com/data), find a regression dataset which sparks your interest and try to model."]},{"cell_type":"markdown","metadata":{"id":"Q0l0dSr_d-r4"},"source":["# [How to fetch Kaggle Datasets into Google Colab](https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a)\n","\n","> You must have a Google as well as a Kaggle account to proceed with the below steps.\n","\n","- Step 1:Get you Kaggle API Token\n","  - Go to Your Account and click on Create New API Token.\n","> A file named kaggle.json will get downloaded containing your username and token key\n","\n","- Step 2: Uploading kaggle.json into Google Drive\n","  - Create a folder named Kaggle where we will be storing our Kaggle datasets\n","  - Upload your kaggle.json file into Kaggle folder\n","\n","\n","- Step 3: Create a new Colab notebook or open a Colab notebook.\n","- Step 4: Mount the Google drive to colab notebook\n",">```\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","```\n","\n","  - Get your authorization code using the URL prompted and provide it. \n","\n","\n","- Step 4: Run the following code to provide the config path to kaggle.json\n","```\n","import os\n","os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n","```\n","> /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive\n","\n","- Step 5: Change your present working directory\n","```\n","#changing the working directory\n","%cd /content/gdrive/My Drive/Kaggle\n","#Check the present working directory using pwd command\n","```\n","\n","- Step 6: Download the kaggle dataset\n","  - Go to kaggle and copy the API Command to download the dataset\n","> Your API Command will look like “kaggle datasets download -d datasnaek/youtube-new”\n","  - Run the following code using ! :\n","> !kaggle datasets download -d datasnaek/youtube-new\n","\n","  - Check the content in your directory using ls command.\n","\n","- Step 7: Unzip your data and remove the zip file\n","  - Use the unzip and rm command\n","```\n","#unzipping the zip files and deleting the zip files\n","!unzip \\*.zip  && rm *.zip\n","```\n","That’s all folks …Now you can use the extracted .csv files with ease directly from your Google Drive.\n","\n","Happy Learning 😃…."]}]}